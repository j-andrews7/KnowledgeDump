{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Thoughts, Rambling, and Code","text":"<p>Sometimes all at once. This site is automatically rendered from markdown documents where I store notes, longform tutorials, and code snippets and functions.</p> <p>Like any bioinformaticist worth their weight, I only want three things - power , fame , and well-designed datasets with proper controls and consistent quality . Not particularly in that order.</p> <p>This site is not going to help with any of that, but hey, it might be fun. Fun, they tell me! </p>"},{"location":"Code_Snippets_Functions/","title":"Useful Code Snippets and Functions","text":"<p>This serves as a collection of code snippets and functions for common data science, bioinformatics, data cleaning/munging, and data visualization tasks. I got sick of hunting through old notebooks and scripts to find that one thing I wrote a year ago.</p>"},{"location":"Code_Snippets_Functions/#r","title":"R","text":""},{"location":"Code_Snippets_Functions/#genepeak-annotations-conversions","title":"Gene/Peak Annotations &amp; Conversions","text":""},{"location":"Code_Snippets_Functions/#convert-ensembl-gene-ids-to-symbols-or-vice-versa","title":"Convert Ensembl Gene IDs to Symbols (or vice versa)","text":"<p>There's like 45 ways to do this, but these are pretty easy with a decent recovery rate. Note that the <code>mygene</code> approach will just return the top hit, which may not be a perfect match to the query, e.g. symbols like \"SOST\" may return \"SOSTDC1\" as the top hit. The <code>ensembldb</code> approach is generally more robust.</p> Using mygeneUsing ensembldb <pre><code>library(mygene)\n\n# Species can be set with `query` and `queryMany`. Symbol to ensembl.\n# Set `fields = \"all\"` to get all the info available.\ndf &lt;- queryMany(c(\"Cdk2\", \"Cdk3\"), fields = c(\"ensembl.gene\", \"entrezgene\"), species = \"mouse\", size = 1)\ndf$ensembl.gene\n</code></pre> <pre><code>library(ensembldb)\nlibrary(EnsDb.Mmusculus.v79)\n\nens.ids &lt;- c(\"ENSMUSG00000025907\")\n\nsymbs &lt;- mapIds(EnsDb.Mmusculus.v79, keys = ens.ids, keytype = \"GENEID\", column = \"SYMBOL\")\nsymbs\n</code></pre>"},{"location":"Code_Snippets_Functions/#gene-summaries","title":"Gene Summaries","text":"<p>Refseq description summaries. Can use almost any ID for these, does a decent job figuring it out.</p> <pre><code>library(mygene)\n\n# One gene.\ngene &lt;- query(\"CDK2\", fields = \"all\", size = 1)\ngene$hits$summary\n\n\n# Multiple genes. Returns a dataframe. Set `fields = \"all\"` to get all the info available.\ndf &lt;- queryMany(c(1017, 1018, \"ENSG00000148795\", \"LAIR1\"), \n               fields = c(\"symbol\", \"name\", \"taxid\", \"entrezgene\", \"summary\"), size = 1)\ndf$summary\n</code></pre>"},{"location":"Code_Snippets_Functions/#convert-human-to-mouse-gene-orthologs","title":"Convert human to mouse gene orthologs","text":"Using babelgeneUsing biomartUsing JAX homolog list <pre><code>library(babelgene)\northologs(genes, species, human = TRUE, min_support = 3, top = TRUE)\n</code></pre> <pre><code>library(biomart)\nconvertHumanGeneList &lt;- function(x) {\n   human &lt;- useMart(\"ensembl\", dataset = \"hsapiens_gene_ensembl\")\n  mouse &lt;- useMart(\"ensembl\", dataset = \"mmusculus_gene_ensembl\")\n  genesV2 &lt;- getLDS(attributes = c(\"hgnc_symbol\"), filters = \"hgnc_symbol\", values = x , \n      mart = human, attributesL = c(\"mgi_symbol\"), martL = mouse, uniqueRows=T)\n  humanx &lt;- unique(genesV2[, 2])\n  return(humanx)\n}\ngenes &lt;- convertMouseGeneList(humGenes)\n</code></pre> <pre><code>library(dplyr)\nmouse_human_genes = read.csv(\"http://www.informatics.jax.org/downloads/reports/HOM_MouseHumanSequence.rpt\",sep=\"\\t\")\n\nconvert_mouse_to_human &lt;- function(gene_list) {\n\n  output = c()\n\n  for(gene in gene_list){\n    class_key = (mouse_human_genes %&gt;% \n        filter(Symbol == gene &amp; Common.Organism.Name==\"mouse, laboratory\"))[['DB.Class.Key']]\n    if(!identical(class_key, integer(0))) {\n      human_genes = (mouse_human_genes %&gt;% \n          filter(DB.Class.Key == class_key &amp; Common.Organism.Name==\"human\"))[,\"Symbol\"]\n      for(human_gene in human_genes){\n        output = append(output,human_gene)\n      }\n    }\n  }\n\n  return (output)\n}\n\nconvert_human_to_mouse &lt;- function(gene_list){\n\n  output = c()\n\n  for(gene in gene_list){\n    class_key = (mouse_human_genes %&gt;% filter(Symbol == gene &amp; Common.Organism.Name==\"human\"))[['DB.Class.Key']]\n    if(!identical(class_key, integer(0)) ){\n      mouse_genes = (mouse_human_genes %&gt;% filter(DB.Class.Key == class_key &amp; Common.Organism.Name==\"mouse, laboratory\"))[,\"Symbol\"]\n      for(mouse_gene in mouse_genes){\n        output = append(output, mouse_gene)\n      }\n    }\n  }\n\n  return (output)\n}\n</code></pre> <p>Biomart goes down pretty often, so the <code>babelgene</code> option is more reliable.</p>"},{"location":"Code_Snippets_Functions/#viz","title":"Viz","text":""},{"location":"Code_Snippets_Functions/#3d-tsneumappcadiffusion-map","title":"3D tSNE/UMAP/PCA/Diffusion Map","text":"<p>Occasionally, 3D dimensionality reduction plots can be kind of useful for exploratory purposes.</p> <pre><code>library(plotly)\nlibrary(SingleCellExperiment)\nlibrary(dittoSeq)\nlibrary(htmlwidgets)\nlibrary(shinyjqui)\n\n\n#' @param sce SingleCellExperiment object.\n#' @param dimred Character scalar indicating the name of the dimensionality reduction to plot.\n#' @param color.by Character scalar indicating colData column to color points by.\n#' @param shape.by Character scalar indicating colData column to shape points by.\n#' @param hover.info Character scalar or vector indicating colData column(s) \n#'   to display when points are hovered.\n#' @param pt.size Numeric scalar indicating point size.\nplot3Ddim &lt;- function(sce, dimred, color.by = NULL, shape.by = NULL, \n                      hover.info = NULL, pt.size = 3) {\n\n  dimmy &lt;- as.data.frame(reducedDim(sce, dimred))\n  names(dimmy) &lt;- paste0(dimred, \"_\", 1:3)\n\n  pl.shapes &lt;- NULL\n  pl.cols &lt;- NULL\n  pl.col &lt;- \"black\"\n\n  if (!is.null(color.by)) {\n    pl.cols &lt;- colData(sce)[,color.by, drop = TRUE]\n\n    if (is.factor(pl.cols)) {\n      pl.cols &lt;- droplevels(pl.cols)\n    }\n  }\n\n  if (!is.null(shape.by)) {\n    pl.shapes &lt;- colData(sce)[,shape.by, drop = TRUE]\n\n    if (is.factor(pl.cols)) {\n      pl.shapes &lt;- droplevels(pl.shapes)\n    }\n  }\n\n  pl.col &lt;- dittoColors()[seq_along(unique(colData(sce)[,color.by, drop = TRUE]))]\n\n  hov.text &lt;- NULL\n\n  if (!is.null(hover.info)) {\n    hov &lt;- list()\n    for (i in seq_along(hover.info)) {\n      hov[[i]] &lt;- paste0(\"&lt;/br&gt;&lt;b&gt;\",hover.info[i], \":&lt;/b&gt; \", \n                         colData(sce)[[hover.info[i]]])\n    }\n\n    hov.text &lt;- do.call(paste0, hov)\n  }\n\n  # Generate plot.\n  fig &lt;- plot_ly(dimmy, x = as.formula(paste0(\"~\", dimred, \"_1\")),\n          y = as.formula(paste0(\"~\", dimred, \"_2\")),\n          z = as.formula(paste0(\"~\", dimred, \"_3\")),\n          type = \"scatter3d\",\n          mode = \"markers\",\n          color = pl.cols,\n          colors = pl.col,\n          size = pt.size,\n          symbol = pl.shapes,\n          symbols = c(\"circle\", \"square\", \"diamond\", \"cross\", \"diamond-open\",\n                      \"circle-open\", \"square-open\", \"x\"),\n          text = hov.text,\n          hoverinfo = \"text\") %&gt;%\n    layout(scene = list(\n      xaxis = list(title = paste0(dimred, \"_1\")),\n      yaxis = list(title = paste0(dimred, \"_2\")),\n      zaxis = list(title = paste0(dimred, \"_3\")),\n      camera = list(eye = list(x=1.5, y = 1.8, z = 0.4)))) %&gt;%\n    toWebGL()\n\n  return(fig)\n}\n\nfig &lt;- plot3Ddim(new.sce, \"UMAP_m.dist0.3_n.neigh10\", \n                 color.by = \"Group\", hover.info = c(\"CellType\", \"Group\"))\n\n# Self as self-contained html if wanted.\nsaveWidget(jqui_resizable(fig), \"./QC/UMAP.3D.m.dist0.3_n.neigh10.Group.html\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#gene-expression-over-time-or-between-groups","title":"Gene Expression Over Time (or Between Groups)","text":"<p>Useful for time-series RNA-seq and such.</p> <pre><code>library(dittoSeq)\nlibrary(ggplot2)\n\n# Single gene. Add \"method = 'lm'\" to 'geom_smooth' for straight-line trend.\ndittoPlot(dds, \"Clu\", group.by = \"Broad_Group\", color.by = \"H3_Status\", split.by = \"Location\", \n          assay = \"lognorm\", swap.rownames = \"SYMBOL\", adjustment = NULL, \n          plots = c(\"boxplot\", \"jitter\"), boxplot.width = 0.6, boxplot.lineweight = 0.5, \n          ylab = \"log2(normalized counts + 1)\") + \n          geom_smooth(aes(group = color, color = color), se = FALSE, linewidth = 1.5) + \n          scale_color_manual(values = Darken(dittoColors()[1:2]))\n\n# Group of genes.\ndittoPlotVarsAcrossGroups(dds, c(\"Cdk2\", \"Jun\", \"Fos\", \"Fcmr\"), group.by = \"Broad_Group\", \n                          color.by = \"H3_Status\", split.by = \"Location\", assay = \"lognorm\", \n                          swap.rownames = \"SYMBOL\", adjustment = NULL, plots = c(\"boxplot\", \"jitter\"), \n                          boxplot.width = 0.6, main = \"Jessa.Pons.RGC_and_progenitor\", \n                          boxplot.lineweight = 0.5) + \n                          geom_smooth(aes(group = color, color = color), se = FALSE, linewidth = 1.5) + \n                          scale_color_manual(values = Darken(dittoColors()[1:2]))\n</code></pre>"},{"location":"Code_Snippets_Functions/#plotly-subplot-orientation-mirroring","title":"plotly Subplot Orientation Mirroring","text":"<p>For when you want multiple subplots to mirror each other in terms of orientation. Note that <code>scene</code> must be set properly in each <code>plot_ly</code> call.</p> <pre><code>library(plotly)\n\npal &lt;- c(\"#18B803\", \"#138901\", \"#b3b3b3\", \"#5A5A5A\")\npal &lt;- setNames(pal, c(\"s1\", \"s2\", \"s3\", \"s4\"))\n\nfig1 &lt;- mdf.rpca %&gt;% plot_ly(x = ~DC1, y = ~DC2, z = ~DC3, color = ~sample, mode = \"markers\", \n                             marker = list(size = 3), scene = \"scene1\", colors = pal) %&gt;% \n     layout(annotations = list(x = 0.2 , y = 1.05, text = \"sample\", showarrow = F, \nxref='paper', yref='paper'))\n\nfig2 &lt;- mdf.rpca %&gt;% plot_ly(x = ~DC1, y = ~DC2, z = ~DC3, color = ~Vim, mode = \"markers\", \n                             marker = list(size = 3), scene = \"scene2\") %&gt;% \n     layout(annotations = list(x = 0.2 , y = 1.05, text = \"Vim\", showarrow = F, \nxref='paper', yref='paper'))\n\nfig3 &lt;- mdf.rpca %&gt;% plot_ly(x = ~DC1, y = ~DC2, z = ~DC3, color = ~Mbp, mode = \"markers\", \n                             marker = list(size = 3), scene = \"scene3\") %&gt;% \n     layout(annotations = list(x = 0.2 , y = 1.05, text = \"Mbp\", showarrow = F, \nxref='paper', yref='paper'))\n\nfig4 &lt;- mdf.rpca %&gt;% plot_ly(x = ~DC1, y = ~DC2, z = ~DC3, color = ~Pdgfra, mode = \"markers\", \n                             marker = list(size = 3), scene = \"scene4\") %&gt;% \n     layout(annotations = list(x = 0.2 , y = 1.05, text = \"Pdgfra\", showarrow = F, \nxref='paper', yref='paper'))\n\nfig5 &lt;- mdf.rpca %&gt;% plot_ly(x = ~DC1, y = ~DC2, z = ~DC3, color = ~Plp1, mode = \"markers\", \n                             marker = list(size = 3), scene = \"scene5\") %&gt;% \n     layout(annotations = list(x = 0.2 , y = 1.05, text = \"Plp1\", showarrow = F, \nxref='paper', yref='paper'))\n\nfig6 &lt;- mdf.rpca %&gt;% plot_ly(x = ~DC1, y = ~DC2, z = ~DC3, color = ~Fyn, mode = \"markers\", \n                             marker = list(size = 3), scene = \"scene6\") %&gt;% \n     layout(annotations = list(x = 0.2 , y = 1.05, text = \"Fyn\", showarrow = F, \nxref='paper', yref='paper'))\n\nmain_plot &lt;- subplot(fig1, fig2, fig3, fig4, fig5, fig6, nrows = 2, margin = 0.06) %&gt;% \n  layout(\n         scene  = list(domain = list(x = c(0, 0.33), y = c(0.5, 1)), aspectmode = \"cube\"), \n         scene2 = list(domain = list(x = c(0.33, 0.66), y = c(0.5, 1)), aspectmode = \"cube\"),\n         scene3 = list(domain = list(x = c(0.66, 1), y = c(0.5, 1)), aspectmode = \"cube\"),\n         scene4 = list(domain = list(x = c(0, 0.33), y = c(0, 0.5)), aspectmode = \"cube\"),\n         scene5 = list(domain = list(x = c(0.33, 0.66), y = c(0, 0.5)), aspectmode = \"cube\"),\n         scene6 = list(domain = list(x = c(0.66, 1), y = c(0, 0.5)), aspectmode = \"cube\")\n  )\n\nmain_plot &lt;- main_plot %&gt;% \n  htmlwidgets::onRender(\n    \"function(x, el) {\n      x.on('plotly_relayout', function(d) {\n        const camera = Object.keys(d).filter((key) =&gt; /\\\\.camera$/.test(key));\n        if (camera.length) {\n          const scenes = Object.keys(x.layout).filter((key) =&gt; /^scene\\\\d*/.test(key));\n          const new_layout = {};\n          scenes.forEach(key =&gt; {\n            new_layout[key] = {...x.layout[key], camera: {...d[camera]}};\n          });\n          Plotly.relayout(x, new_layout);\n        }\n      });\n    }\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#plotly-change-plot-order-of-traces","title":"plotly change plot order of traces","text":"<p>In R, plotly doesn't have a built-in way to define plotting order of traces (i.e. different groups), which can result in frustration if you want certain points plotted on top. Thankfully, this can be manually altered by setting the factor levels of the coloring variable.</p> <pre><code>library(plotly)\n\ndd &lt;- data.frame(x = rnorm(1000, 5, 0.5), y = rnorm(1000, 18, 0.2), \n                 group = c(rep(\"A\", 500), rep(\"B\", 500)))\nfig &lt;- plot_ly(data = dd, x = ~x, y = ~y, color = ~group, size = 7, \n               opacity = 1, mode = \"markers\", type = \"scatter\", marker = list(opacity = 1))\n\n# Note the overlapping points\nfig\n\n# Swap the group order in the dataframe.\ndd$group &lt;- factor(dd$group, levels = c(\"B\", \"A\"))\nfig &lt;- plot_ly(data = dd, x = ~x, y = ~y, color = ~group, size = 7, \n               opacity = 1, mode = \"markers\", type = \"scatter\", marker = list(opacity = 1))\n\n# Group 'A' now plotted on top of 'B'.\nfig\n\n# If using ggplotly, something like this can also sometimes work without messing with the upstream data.\nfig$x$data &lt;- rev(fix$x$data)\n</code></pre>"},{"location":"Code_Snippets_Functions/#a-note-on-plotly-layout-and-addition-of-shapes","title":"A note on plotly <code>layout</code>  and addition of shapes","text":"<p>The <code>layout</code> function in R plotly cannot be called multiple times to additively add shapes (like arbitrary lines, etc) to a plot. They must be pre-defined and added all at once. See this issue for more details.</p>"},{"location":"Code_Snippets_Functions/#single-cell-rna-seq","title":"Single Cell RNA-seq","text":""},{"location":"Code_Snippets_Functions/#dimreduc-sweep","title":"dimReduc Sweep","text":"<p>To get lots of dimensionality reductions with differing parameters.</p> <pre><code>library(SingleCellExperiment)\nlibrary(scater)\nlibrary(BiocParallel)\n\n#' @param sce SingleCellExperiment object.\n#' @param dimred Character scalar indicating the name of the dimensionality reduction to use as input.\n#' @param min_dist Numeric vector indicating parameters to sweep for min_dist UMAP parameter.\n#' @param n_neighbors Numeric vector indicating parameters to sweep for n_neighbors UMAP parameter.\n#' @param spread Numeric vector indicating parameters to sweep for spread UMAP parameter. \n#'   In combination with min_dist, this controls the \"clumpiness\" of the cells.\n#' @param BPPARAM BiocParallelParam object to use for parallelization.\numap_sweep &lt;- function(sce, dim_reduc, \n                       min_dist = c(0.01, 0.02, 0.05, 0.1, 0.2, 0.3), \n                       n_neighbors = c(10, 15, 20, 30, 40, 50),\n                       spread = c(0.8, 1, 1.2),\n                       BPPARAM = BiocParallel::bpparam()\n                       ) {\n\n  for (d in min_dist) {\n    for (n in n_neighbors) {\n      for (sp in spread) {\n        message(\"Running UMAP with min_dist = \", d, \", n_neighbors = \", n, \", spread = \", sp)\n        sce &lt;- runUMAP(sce, n_neighbors = n, min_dist = d, spread = sp,\n                       name = paste0(\"UMAP_m.dist\", d, \"_n.neigh\", n, \"_spread\", sp), \n                       dimred = dim_reduc, ncomponents = 2, BPPARAM = BPPARAM)\n      }\n    }\n  }\n\n  return(sce)\n}\n\nsce &lt;- umap_sweep(sce, dim_reduc = \"PCA\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#cluster-sweep","title":"cluster Sweep","text":"<p>To get lots of different clustering sets with different methods/parameters.</p> <pre><code>library(SingleCellExperiment)\nlibrary(scater)\nlibrary(bluster)\nlibrary(dittoSeq)\n\nout &lt;- clusterSweep(reducedDim(sce, \"PCA\"), \n    NNGraphParam(), \n    k=as.integer(c(10, 15, 20, 25, 30, 35, 40)),\n    cluster.fun=c(\"louvain\", \"walktrap\"))\n\n# Cluster metrics\ndf &lt;- as.data.frame(out$parameters)\ndf$num.clusters &lt;- vapply(as.list(out$clusters), function(cluster) { \n    length(unique(cluster))\n}, 0L)\n\nall.sil &lt;- lapply(as.list(out$clusters), function(cluster) {\n    sil &lt;- approxSilhouette(reducedDim(new.sce), cluster)\n    mean(sil$width)\n})\ndf$silhouette &lt;- unlist(all.sil)\n\nall.wcss &lt;- lapply(as.list(out$clusters), function(cluster) {\n    sum(clusterRMSD(reducedDim(new.sce), cluster, sum=TRUE), na.rm=TRUE)\n})\ndf$wcss &lt;- unlist(all.wcss)\n\n# Plotting cluster metrics\npdf(\"./QC/clustering.corr.pdf\", height = 4, width = 12)\ngridExtra::grid.arrange(\n    ggplot(df, aes(x=k, y=num.clusters, group=cluster.fun, color=cluster.fun)) + \n        geom_line(lwd=2) + scale_y_log10(),\n    ggplot(df, aes(x=k, y=silhouette, group=cluster.fun, color=cluster.fun)) + \n        geom_line(lwd=2),\n    ggplot(df, aes(x=k, y=wcss, group=cluster.fun, color=cluster.fun)) + \n        geom_line(lwd=2),\n    ncol=3\n)\ndev.off()\n\n# Add to SCE object.\ncelldata &lt;- colData(sce)\ncolData(sce) &lt;- cbind(celldata, out$clusters)\n</code></pre>"},{"location":"Code_Snippets_Functions/#diffusion-maps","title":"Diffusion Maps","text":"<p>These retain lineage structure more cleanly than UMAP, etc. Often worth subsetting object to lineage of interest before running. There are a few ways to run this - on all variable genes, on PCA components, etc. Recommended to try the variable genes first, though it takes a long while to run.</p> <pre><code>library(destiny)\n\n# Starting from a SingleCellExperiment object\n# Create expressionSet so that phenotype data is carried along.\ncts &lt;- as.matrix(logcounts(sce))\nmet &lt;- new(\"AnnotatedDataFrame\", data = as.data.frame(colData(sce)))\nexps &lt;- ExpressionSet(cts, phenoData = met)\nrm(cts)\ndm &lt;- DiffusionMap(exps)\n\ndir.create(\"./destiny/figures\", showWarnings = FALSE, recursive = TRUE)\n\n# The dataframe is useful for 3D plotting.\ndm.df &lt;- as.data.frame(dm)\nreducedDim(sce.new, \"destiny\") &lt;- dm.df[, 1:20]\n\nwrite.csv(dm.df, file = \"./destiny/dm_df.csv\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#downsample-sce","title":"Downsample SCE","text":"<p>For testing stuff on smaller numbers of cells, etc.</p> <pre><code>#' Downsample a SingleCellExperiment object\n#'\n#' @param sce SingleCellExperiment object.\n#' @param ncells Number of cells to downsample to.\n#' @return Downsampled SingleCellExperiment object.\ndownsampleSCE &lt;- function(sce, ncells) {\n    keep &lt;- sample(seq(1,ncol(sce),by=1), ncells, replace=FALSE)\n    return(sce[,keep])\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#gsea","title":"GSEA","text":""},{"location":"Code_Snippets_Functions/#high-throughput-functions-with-plotting","title":"High-throughput Functions with Plotting","text":"<p>This will run through a bunch of named lists containing genesets and run GSEA on them, yielding both text output for each geneset collection and plots. Two variants, one specific for <code>msigdbr</code> genesets (<code>runGSEA</code>), one for custom genesets (<code>runCustomGSEA</code>).</p> <p>I'll write a tutorial for doing this end-to-end eventually.</p> <pre><code>library(\"fgsea\")\nlibrary(\"msigdbr\")\nlibrary(\"dplyr\")\nlibrary(\"gridExtra\")\nlibrary(\"BiocParallel\")\n\n#' Run Gene Set Enrichment Analysis (GSEA) with MSigDb signatures\n#'\n#' This function performs GSEA on a named list of ranked genes, and restricts the analysis to specific MSigDb \n#' collections of gene signatures using the 'cats' and 'subcats' arguments.\n#'\n#' @param msigs A dataframe containing all MSigDb gene signatures.\n#' @param ranked.genes A named list of ranked genes.\n#' @param outdir The output directory for results.\n#' @param outprefix The prefix for output files.\n#' @param xlsx A list to store results that will be later written to an Excel file. Defaults to NULL.\n#' @param cats A character vector specifying the main categories of gene sets to consider from MSigDb. Defaults to \"H\".\n#' @param subcats A character vector specifying the subcategories of gene sets to consider from MSigDb. \n#'   Must match in length with 'cats'. Defaults to NULL.\n#' @param ... Additional arguments to pass to the 'fgsea' function.\n#'\n#' @return A list of GSEA results if 'xlsx' is not NULL, otherwise, results are saved as files in the specified output directory.\n#'\n#' @examples\n#' \\dontrun{\n#' runGSEA(msigs = msigdb, ranked.genes = my_genes, outdir = \"./results\", outprefix = \"experiment1\", \n#'         xlsx = list(), cats = c(\"H\", \"C3\"), subcats = c(\"BP\", \"MIR\"))\n#' }\n#' \n#' @note Ensure that 'cats' and 'subcats' vectors have equal lengths.\n#' @note The function creates various output files including detailed GSEA results, \n#'   enrichment plots, and tables of top enriched pathways.\n#' \n#' @author Jared Andrews\nrunGSEA &lt;- function(msigs, ranked.genes, outdir, outprefix, \n                    xlsx = NULL, cats = \"H\", subcats = NULL, ...) {\n  if (length(cats) != length(subcats)) {\n    stop(\"cats and subcats must be of equal length\")\n  }\n\n  collapsedPathways &lt;- NULL\n\n  for (i in seq_along(cats)) {\n\n    # Parse out the category and subcategory, set output prefixes.\n    subcat &lt;- NULL\n    categ &lt;- cats[i]\n    if (!is.null(subcats) &amp; subcats[i] != \"\") {\n      subcat &lt;- subcats[i]\n      sigs &lt;- msigs %&gt;% dplyr::filter(gs_cat == categ &amp; gs_subcat == subcat)\n      outpre &lt;- paste0(outdir, \"/\", outprefix, \".\", categ, \".\", subcat)\n      outpre &lt;- gsub(\":\", \".\", outpre)\n      xlname &lt;- paste0(outprefix, \".\", categ, \".\", subcat)\n      xlname &lt;- gsub(\":\", \".\", xlname)\n    } else {\n      sigs &lt;- msigs %&gt;% dplyr::filter(gs_cat == categ)\n      outpre &lt;- paste0(outdir, \"/\", outprefix, \".\", categ)\n      xlname &lt;- paste0(outprefix, \".\", categ)\n    }\n\n    # Convert the msigdbr dataframe to named lists containing the gene sets in the set category.\n    sigs &lt;- sigs %&gt;% split(x = .$gene_symbol, f = .$gs_name)\n    fgseaRes &lt;- fgsea(pathways = sigs, \n                  stats    = ranked.genes,\n                  eps      = 1e-100,\n                  minSize  = 15,\n                  maxSize  = 1000,\n                  ...)\n    fgseaRes &lt;- fgseaRes[order(padj),]\n\n    # Save full results.\n    fwrite(fgseaRes, file=paste0(outpre, \".fgseaRes.txt\"), sep=\"\\t\", sep2=c(\"\", \" \", \"\"))\n\n    # Figures\n    fsig &lt;- fgseaRes$pathway[fgseaRes$padj &lt; 0.05]\n    plots &lt;- list()\n    for (f in seq_along(fsig)) {\n      pathw &lt;- fsig[f]\n      if (!is.na(pathw)) {\n        # Adjust corner that stats will be plotted in based on swoop shape.\n        if (!is.na(fgseaRes$NES[f]) &amp; fgseaRes$NES[f] &lt; 0) {\n          xinf &lt;- -Inf\n          yinf &lt;- -Inf\n        } else {\n          xinf &lt;- Inf\n          yinf &lt;- Inf\n        }\n\n        # For those really long titles.\n        tt &lt;- pathw\n        if (nchar(tt) &gt; 40) {\n          stri_sub(tt, 48, 47) &lt;- \"\\n\"\n        } \n\n        p &lt;- plotEnrichment(sigs[[pathw]],\n                ranked.genes) + labs(title = tt) + \n        theme(plot.title = element_text(size=6))\n\n        # Add stats to plot.\n        p &lt;- p + annotate(\"text\", xinf, yinf,\n                          label = paste0(\"p.val = \",\n                                         formatC(fgseaRes$pval[fgseaRes$pathway == pathw],\n                                                 format = \"e\", digits = 2),\n                                         \"\\np.adj = \",\n                                         formatC(fgseaRes$padj[fgseaRes$pathway == pathw],\n                                               format = \"e\", digits = 2),\n                                         \"\\nNES = \",\n                                         round(fgseaRes$NES[fgseaRes$pathway == pathw], digits = 2)),\n                        vjust = \"inward\", hjust = \"inward\", size = 3)\n        plots[[f]] &lt;- p\n      }\n    }\n\n    if (length(plots) &gt; 0) {\n      pdf(paste0(outpre, \".Pathways.padj0.05.Swoops.pdf\"), height = 10, width = 20)\n      # Calculate how many pages to print assuming max 24 plots per page.\n      pages &lt;- ceiling(length(plots)/24)\n      # Print each page.\n      for (i in 1:pages) {\n        end &lt;- i * 24\n        start &lt;- end - 23\n        if (end &gt; length(plots)) {\n          end &lt;- length(plots)\n        }\n        grid.arrange(grobs = plots[start:end], nrow = 4, ncol = 6)\n      }\n      dev.off()\n    }\n\n    # Add results to named list.\n    if (!is.null(xlsx)) {\n      xlsx[[xlname]] &lt;- fgseaRes\n    }\n  }\n  if (!is.null(xlsx)) {\n      return(xlsx)\n  }\n}\n\n#' Run Gene Set Enrichment Analysis (GSEA) with custom signatures\n#'\n#' This function performs GSEA on a named list of ranked genes.\n#'\n#' @param sigs A named list of gene signatures.\n#' @param ranked.genes A named list of ranked genes.\n#' @param outdir The output directory for results.\n#' @param outprefix The prefix for output files.\n#' @param xlsx A list to store results that will be later written to an Excel file. Defaults to NULL.\n#' @param ... Additional arguments to pass to the 'fgsea' function.\n#'\n#' @return A list of GSEA results if 'xlsx' is not NULL, otherwise, results are saved as files in the specified output directory.\n#'\n#' @examples\n#' \\dontrun{\n#' runCustomGSEA(msigs = msigdb, ranked.genes = my_genes, outdir = \"./results\", outprefix = \"experiment1\", \n#'         xlsx = list())\n#' }\n#' \n#' @note The function creates various output files including detailed GSEA results, enrichment plots, and tables of top enriched pathways.\n#' \n#' @author Jared Andrews\nrunCustomGSEA &lt;- function(sigs, ranked.genes, outdir, \n                          outprefix, xlsx = NULL, ...) {\n  # Basically the same function as above except 'sigs' is just\n  # a named list of gene sets.\n\n  outpre &lt;- paste0(outdir, \"/\", outprefix, \".c\")\n  xlname &lt;- paste0(outprefix, \".c\")\n\n  fgseaRes &lt;- fgsea(pathways = sigs, \n                stats    = ranked.genes,\n                eps      = 1e-100,\n                minSize  = 15,\n                maxSize  = 3000,\n                ...)\n  fgseaRes &lt;- fgseaRes[order(padj),]\n\n  # Save full results.\n  fwrite(fgseaRes, file=paste0(outpre, \".fgseaRes.txt\"), \n         sep=\"\\t\", sep2=c(\"\", \" \", \"\"))\n\n  # Figures\n  fsig &lt;- fgseaRes$pathway\n  plots &lt;- list()\n  for (f in seq_along(fsig)) {\n    pathw &lt;- fsig[f]\n    if (!is.na(pathw)) {\n\n      # reposition annotation depending on curve shape.\n      if (!is.na(fgseaRes$NES[f]) &amp; fgseaRes$NES[f] &lt; 0) {\n        xinf &lt;- -Inf\n        yinf &lt;- -Inf\n      } else {\n        xinf &lt;- Inf\n        yinf &lt;- Inf\n      }\n\n      # For those really long titles.\n      tt &lt;- pathw\n      if (nchar(tt) &gt; 40) {\n        stri_sub(tt, 48, 47) &lt;- \"\\n\"\n      } \n\n      p &lt;- plotEnrichment(sigs[[pathw]],\n              ranked.genes) + labs(title=tt) + \n        theme(plot.title = element_text(size=7))\n\n      # Add stats to plot.\n      p &lt;- p + annotate(\"text\", xinf, yinf, \n                        label = paste0(\"p.val = \", \n                                       formatC(fgseaRes$pval[f], format = \"e\", digits = 2), \n                                       \"\\np.adj = \", \n                                       formatC(fgseaRes$padj[f], format = \"e\", digits = 2), \n                                       \"\\nNES = \",\n                                       round(fgseaRes$NES[f], digits = 2)),\n                        vjust = \"inward\", hjust = \"inward\", size = 3)\n\n      plots[[f]] &lt;- p\n    }\n  }\n\n  pdf(paste0(outpre, \".Pathways.padj0.05.Swoops.pdf\"), height = 10, width = 20)\n  # Calculate how many pages to print assuming max 24 plots per page.\n  pages &lt;- ceiling(length(plots)/24)\n  # Print each page.\n  for (i in 1:pages) {\n    end &lt;- i * 24\n    start &lt;- end - 23\n    if (end &gt; length(plots)) {\n      end &lt;- length(plots)\n    }\n    grid.arrange(grobs = plots[start:end], nrow = 4, ncol = 6)\n  }\n  dev.off()\n\n  if (!is.null(xlsx)) {\n    xlsx[[xlname]] &lt;- fgseaRes\n  }\n\n  if (!is.null(xlsx)) {\n    return(xlsx)\n  }\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#summarization","title":"Summarization","text":"<p>The above is nice for generate results for all the significant hits, but it's not a great summary of them. The below will take those results and plot the top X number of significant genesets, ranked by adjusted p-value, for each collection as a plot.</p> <pre><code>#' Summarize Gene Set Enrichment Analysis (GSEA) Results\n#'\n#' This function summarizes GSEA results by selecting the top significant gene sets. It creates an output directory\n#' and saves the summarized results into this directory.\n#'\n#' @param gsea.list A list of GSEA results as returned by `runGSEA` or `runCustomGSEA`.\n#' @param outdir The output directory for summarized results.\n#' @param padj.th The significance threshold (adjusted p-value) for filtering gene sets. Defaults to 0.05.\n#' @param top The number of top significant gene sets to consider. Defaults to 75.\n#'\n#' @return Invisible. The function creates an output directory and saves the summarized results there.\n#'\n#' @examples\n#' \\dontrun{\n#' summarize_GSEA(gsea.list = my_gsea_results, outdir = \"./summary\", padj.th = 0.01, top = 50)\n#' }\n#'\n#' @author Jared Andrews\nsummarize_GSEA &lt;- function(gsea.list, outdir, padj.th = 0.05, top = 75) {\n  dir.create(outdir, showWarnings = FALSE, recursive = TRUE)\n\n  for (i in seq_along(gsea.list)) {\n    ct &lt;- names(gsea.list)[i]\n    df &lt;- gsea.list[[i]]\n\n    df.sub &lt;- df[df$padj &lt; padj.th,]\n\n    if (nrow(df.sub) &gt; top) {\n      df.sub &lt;- df.sub %&gt;% as_tibble() %&gt;% arrange(padj)\n      df.sub &lt;- df.sub[1:top, ]\n    }\n\n    if (nrow(df.sub) &gt; 0) {\n      df.sub &lt;- df.sub %&gt;%\n        as_tibble() %&gt;%\n        arrange(desc(NES))\n\n      p &lt;- ggplot(df.sub, aes(reorder(pathway, -NES), NES)) +\n        geom_col(aes(fill=-log10(padj))) + coord_flip() +\n        labs(x=NULL, y=\"Normalized Enrichment Score\", \n             title=paste0(ct, \" - Top \", top, \"\\np.adj &lt; \", padj.th)) + \n        theme_bw() + scale_fill_viridis() + ylim(-4,4) + \n        theme(axis.text.y = element_text(size = 6), plot.title = element_text(size = 10)) +\n        scale_x_discrete(label = function(x) str_trunc(x, 55))\n\n      h &lt;- 2 + (0.07 * nrow(df.sub))\n\n      pdf(paste0(outdir, \"/\", ct, \".padj.\", padj.th, \".topbypadj\", top, \".revrank.pdf\"), width = 7, height = h)\n      print(p)\n      dev.off()\n    }\n  }\n}\n\nsummarize_GSEA(xl.lists, outdir = \"./GSEA/RA.v.vehicle\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#go-semantic-similarity-heatmaps","title":"GO Semantic Similarity Heatmaps","text":"<p>These cluster GO terms together by their similarity, allowing us to collapse closely related terms together. This is useful for summarizing the broad changes in each comparison.</p> <pre><code>#' Simplify GSEA Results and Generate PDF\n#'\n#' This function simplifies GSEA (Gene Set Enrichment Analysis) results from\n#' GO term genesets based on semantic similarity of the genesets.\n#' It filters categorizes the results returned from fgsea based on the \n#' normalized enrichment score (NES) and adjust p-value.\n#'\n#' @param res Data frame containing the GSEA results from fgsea.\n#' @param msig Data frame containing the gene set metadata.\n#' @param outname Character string specifying the name of the output PDF file. Default is \"simplified_GSEA.pdf\".\n#' @param pos.name Character string specifying the name for positively enriched sets. Default is \"g1_enriched\".\n#' @param neg.name Character string specifying the name for negatively enriched sets. Default is \"g2_enriched\".\n#' @param height Numeric specifying the height of the PDF. Default is 12.\n#' @param width Numeric specifying the width of the PDF. Default is 12.\n#' @param ... Additional parameters to pass to the `simplifyGOFromMultipleLists` function.\n#'\n#' @return NULL. The function generates a PDF file as a side effect.\n#' @author Jared Andrews\n#' \n#' @seealso \\code{\\link[simplifyEnrichment]{simplifyGOFromMultipleLists}}\nsimplify_GSEA &lt;- function(res,\n                          msig,\n                          outname = \"simplified_GSEA.pdf\",\n                          pos.name = \"g1_enriched\",\n                          neg.name = \"g2_enriched\",\n                          height = 12,\n                          width = 12,\n                          ...) {\n  # Check for GO terms\n  res$ID &lt;- msig$gs_exact_source[match(res$path, msig$gs_name)]\n  res$p.adjust &lt;- res$padj\n\n  if (nrow(res) &lt; 5) {\n    message(\"Not enough terms to cluster (&lt;5), skipping.\")\n    return(NULL)\n  }\n\n  pos_res &lt;- res[res$NES &gt; 0, ]\n  neg_res &lt;- res[res$NES &lt; 0, ]\n  lt &lt;- list()\n  lt[[pos.name]] &lt;- pos_res\n  lt[[neg.name]] &lt;- neg_res\n\n  pdf(outname, height = height, width = width)\n  simplifyGOFromMultipleLists(lt, ...)\n  dev.off()\n}\n\nfor (r in c(\"WT.midline.v.hemi.C5.GO.BP\", \"WT.midline.v.hemi.C5.GO.MF\", \"WT.midline.v.hemi.C5.GO.CC\")) {\n  fgsea.res &lt;- xl.lists[[r]]\n  simplify_GSEA(fgsea.res, msig, pos.name = \"midline_enriched\", neg.name = \"hemispheric_enriched\", \n                outname = paste0(\"./GSEA/\", r, \".simplifyHeatmap.pdf\"), padj_cutoff = 0.05, \n                min_term = 2, fontsize_range = c(7, 14), \n                heatmap_param = list(col = c(\"blue\", \"white\", \"red\"), breaks = c(1, 0.05, 0.0005)))\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#plot-leading-edge-genes","title":"Plot Leading Edge Genes","text":"<p>GSEA returns the leading edge genes that are driving the score for a given signature. It can be useful to have a closer look at these genes in the form of boxplots and/or heatmaps.</p> <pre><code>#' Plot Leading Edge Genes from GSEA\n#'\n#' This function plots the leading edge genes from a GSEA analysis, which are the core genes that contribute to \n#' the enrichment signal. These plots can help understand the gene expression patterns in the form of boxplots or heatmaps.\n#'\n#' @param dds A DESeqDataSet object.\n#' @param gsea.lists A list of GSEA results as returned by `runGSEA` or `runCustomGSEA`.\n#' @param annot.by A character string or vector for column name(s) in `colData(dds)` by which to annotate the samples\n#' @param group.by A character string or vector for column name(s) in `colData(dds)` by which to group the samples\n#' @param outdir The directory where the output plots should be saved.\n#' @param use.assay A character string specifying the assay to use from the 'dds' object.\n#' @param cells.use A character vector specifying the cells to include in the plot.\n#' @param sig.thresh The significance threshold (adjusted p-value) for selecting gene sets. Defaults to 0.05.\n#' @param group.by2 A secondary character string or vector for column name(s) in `colData(dds)` to further group the samples. Defaults to NULL.\n#' @param split.by A character string or vector for column name(s) in `colData(dds)` to split the plot into multiple facets. Defaults to NULL.\n#' @param swap.rownames A character string for `rowData` column to switch the rownames (e.g. \"SYMBOL\"). Defaults to NULL.\n#' @param order.by A character string or vector for column name(s) in `colData(dds)` by which to order the samples Defaults to NULL.\n#'\n#' @return Invisible. The function saves the plots to the specified output directory.\n#'\n#' @examples\n#' \\dontrun{\n#' plot_le(dds = my_dds, gsea.lists = my_gsea_results, annot.by = \"group\", group.by = \"condition\", \n#'         outdir = \"./plots\", use.assay = \"counts\", cells.use = c(\"cell1\", \"cell2\"), \n#'         sig.thresh = 0.01, group.by2 = \"timepoint\", split.by = \"treatment\")\n#' }\n#'\n#' @note The function may take a long time to execute if many gene sets are provided.\n#'\n#' @author Jared Andrews\nplot_le &lt;- function(sce, gsea.lists, annot.by, group.by, outdir, use.assay, cells.use, sig.thresh = 0.05, \n                    group.by2 = NULL, split.by = NULL, swap.rownames = NULL) {\n\n  for (i in seq_along(gsea.lists)) {\n    ct &lt;- names(gsea.lists)[i]\n    df &lt;- gsea.lists[[i]]\n\n    sig.paths &lt;- df$pathway[df$padj &lt; sig.thresh]\n\n    dir.create(outdir, showWarnings = FALSE, recursive = TRUE)\n    for (p in seq_along(sig.paths)) {\n      path.name &lt;- sig.paths[p]\n      le &lt;- unlist(df$leadingEdge[df$pathway == path.name])\n\n      if (nchar(path.name) &gt; 50) {\n        path.name &lt;- substr(path.name, 1, 50)\n      }\n\n      if (length(le) &gt; 1) {\n\n        pdf(paste0(outdir, \"/\", ct, \".\", path.name, \".boxplot.pdf\"), width = 5, height = 4)\n\n        for (i in use.assay) {\n          pl &lt;- dittoPlotVarsAcrossGroups(sce[,cells.use], le, group.by = group.by, \n                                          plots = c(\"vlnplot\", \"jitter\", \"boxplot\"), assay = i, sub = i,\n                                          vlnplot.lineweight = 0.4, boxplot.lineweight = 0.5, \n                                          swap.rownames = swap.rownames)\n          print(pl)\n          pl &lt;- dittoPlotVarsAcrossGroups(sce[,cells.use], le, group.by = group.by, \n                                          plots = c(\"vlnplot\", \"jitter\", \"boxplot\"), \n                                          adjustment = \"relative.to.max\", assay = i, sub = i,\n                                          vlnplot.lineweight = 0.4, boxplot.lineweight = 0.5, \n                                          swap.rownames = swap.rownames)\n          print(pl)\n          pl &lt;- dittoPlotVarsAcrossGroups(sce[,cells.use], le, group.by = group.by, \n                                          plots = c(\"vlnplot\", \"jitter\", \"boxplot\"), \n                                          adjustment = \"none\", assay = i, sub = i,\n                                          vlnplot.lineweight = 0.4, boxplot.lineweight = 0.5, \n                                          swap.rownames = swap.rownames)\n          print(pl)\n\n          if (!is.null(group.by2) &amp; !is.null(split.by)) {\n            pl &lt;- dittoPlotVarsAcrossGroups(sce, le, group.by = group.by2, split.by = split.by,\n                                            plots = c(\"vlnplot\", \"jitter\", \"boxplot\"), assay = i, sub = i,\n                                            vlnplot.lineweight = 0.4, boxplot.lineweight = 0.5, \n                                            swap.rownames = swap.rownames)\n            print(pl)\n            pl &lt;- dittoPlotVarsAcrossGroups(sce, le, group.by = group.by2, split.by = split.by,\n                                            plots = c(\"vlnplot\", \"jitter\", \"boxplot\"), \n                                            adjustment = \"relative.to.max\", assay = i, sub = i,\n                                            vlnplot.lineweight = 0.4, boxplot.lineweight = 0.5, \n                                            swap.rownames = swap.rownames)\n            print(pl)\n            pl &lt;- dittoPlotVarsAcrossGroups(sce, le, group.by = group.by2, split.by = split.by,\n                                            plots = c(\"vlnplot\", \"jitter\", \"boxplot\"), \n                                            adjustment = \"none\", assay = i, sub = i,\n                                            vlnplot.lineweight = 0.4, boxplot.lineweight = 0.5, \n                                            swap.rownames = swap.rownames)\n            print(pl)\n          }\n        }\n\n        dev.off()\n\n        pdf(paste0(outdir, \"/\", ct, \".\", path.name, \".heatmap.pdf\"), width = 5, height = 7)\n        for (i in use.assay) {\n          pl &lt;- dittoHeatmap(sce, le, annot.by = annot.by, cells.use = cells.use, show_colnames = FALSE,\n                             breaks = seq(-3, 3, length.out = 51), cluster_rows = FALSE,\n                             fontsize_row = 6, cluster_cols = FALSE, assay = i, sub = i, \n                             swap.rownames = swap.rownames)\n          grid.draw(pl)\n\n          pl &lt;- dittoHeatmap(sce, le, annot.by = annot.by, show_colnames = FALSE,\n                             breaks = seq(-3, 3, length.out = 51), cluster_rows = FALSE,\n                             fontsize_row = 6, cluster_cols = FALSE, assay = i, sub = i, \n                             swap.rownames = swap.rownames)\n          grid.draw(pl)\n        }\n        dev.off()\n      }\n    }\n  }\n}\n\nplot_le(bulk, xl.lists, annot.by = \"Line_Treatment\", group.by = \"Line_Treatment\", group.by2 = \"Treatment\", \n        split.by = \"Line\", outdir = \"./GSEA/LTC115.v.LTC97_DMSO/leading_edge\", use.assay = c(\"lognorm\", \"vsd\"), \n        cells.use = bulk$Line_Treatment %in% c(\"LTC115_DMSO\", \"LTC97_DMSO\", \"LTC115_Primary\", \"LTC97_Primary\"))\n</code></pre>"},{"location":"Code_Snippets_Functions/#plot-individual-enrichment-plot-for-single-pathway","title":"Plot Individual Enrichment Plot for Single Pathway","text":"<p>Useful for making plots for non-significant pathways as comparison in different datasets.</p> <pre><code>#' Create fgsea enrichment plot for single pathway\n#'\n#' @param pathway Vector of gene identifiers in pathway.\n#' @param stats Named vector of gene rank statistics.\n#'   Each element should be named with a gene identifier.\n#' @param pathway.name Optional string to use as plot title and to access fgsea stats.\n#' @param fgsea.res Optional data.frame containing fgsea results as returned by `fgsea`.\n#'   If provided with \\code{pathway.name}, the stats for the pathway can be included on the plot.\n#' @param plot.stats Boolean indicating whether to plot the fgsea stats on the plot if\n#'   \\code{fgsea.res} is provided and \\code{pathway.name} are provided.\n#' @param dge.res Optional data.frame containing differential expression results.\n#'   If provided, the differentially expressed genes will be highlighted in the rugplot.\n#' @param lfc.term Column name in \\code{dge.res} containing log fold change values.\n#'   \"auto\" will attempt to automatically determine the column name.\n#' @param sig.term Column name in \\code{dge.res} containing significance values.\n#'   \"auto\" will attempt to automatically determine the column name.\n#' @param exp.term Column name in \\code{dge.res} containing expression values.\n#'   \"auto\" will attempt to automatically determine the column name.\n#' @param id.term Column name in \\code{dge.res} containing gene identifiers.\n#'   \"rownames\" will use the rownames of \\code{dge.res}.\n#' @param lfc.thresh Numeric value for log fold change threshold to consider\n#'   a gene differentially expressed.\n#' @param sig.thresh Numeric value for significance threshold to consider\n#'   a gene differentially expressed.\n#' @param exp.thresh Numeric value for expression threshold to consider\n#'   a gene differentially expressed.\n#' @param dge.up.color Color to use for ticks in rugplot for upregulated genes.\n#' @param dge.down.color Color to use for ticks in rugplot for downregulated genes.\n#' @param tick.color Color to use for ticks in rugplot.\n#' @param gseaParam Numeric value for GSEA parameter as used in `fgsea`.\n#' @return A plotly plot.\n#'\n#' @importFrom fgsea plotEnrichmentData\n#' @importFrom plotly ggplotly config layout add_annotations %&gt;%\n#' @importFrom ggplot2 geom_line geom_segment aes theme element_blank element_line geom_hline\n#'   labs scale_color_identity geom_ribbon\n#'\n#' @author Jared Andrews\n#' @export\nplot_enrichment &lt;- function(pathway.genes,\n                            stats,\n                            pathway.name = NULL,\n                            fgsea.res = NULL,\n                            plot.stats = TRUE,\n                            dge.res = NULL,\n                            lfc.term = \"auto\",\n                            sig.term = \"auto\",\n                            exp.term = \"auto\",\n                            id.term = \"rownames\",\n                            lfc.thresh = 0,\n                            sig.thresh = 0.05,\n                            exp.thresh = 0,\n                            dge.up.color = \"red\",\n                            dge.down.color = \"blue\",\n                            tick.color = \"black\",\n                            gseaParam = 1) {\n    # Parameter validation\n    # TODO: move this to a separate function\n    if (!is.null(dge.res)) {\n        dge.cols &lt;- colnames(dge.res)\n\n        if (lfc.term == \"auto\") {\n            if (!any(dge.cols %in% c(\"log2FoldChange\", \"logFC\", \"LFC\"))) {\n                stop(\"Cannot determine significance term, please provide the column name to lfc.term\")\n            } else {\n                lfc.term &lt;- dge.cols[dge.cols %in% c(\"log2FoldChange\", \"logFC\", \"LFC\")]\n                # If multiple matches, just use first\n                if (length(lfc.term) &gt; 1) {\n                    lfc.term &lt;- lfc.term[1]\n                }\n            }\n        }\n\n        if (sig.term == \"auto\") {\n            if (!any(dge.cols %in% c(\"padj\", \"FDR\", \"svalue\", \"adj.P.Val\"))) {\n                stop(\"Cannot determine significance term, please provide the column name to sig.term\")\n            } else {\n                sig.term &lt;- dge.cols[dge.cols %in% c(\"padj\", \"FDR\", \"svalue\", \"adj.P.Val\")]\n                # If multiple matches, just use first\n                if (length(sig.term) &gt; 1) {\n                    sig.term &lt;- sig.term[1]\n                }\n            }\n        }\n\n        if (exp.term == \"auto\") {\n            if (!any(dge.cols %in% c(\"baseMean\", \"logCPM\", \"AveExpr\"))) {\n                stop(\"Cannot determine significance term, please provide the column name to exp.term\")\n            } else {\n                exp.term &lt;- dge.cols[dge.cols %in% c(\"baseMean\", \"logCPM\", \"AveExpr\")]\n                # If multiple matches, just use first\n                if (length(exp.term) &gt; 1) {\n                    exp.term &lt;- exp.term[1]\n                }\n            }\n        }\n    }\n\n    # Plot data.\n    pd &lt;- plotEnrichmentData(pathway = pathway.genes, stats = stats, gseaParam = gseaParam)\n\n    rnk &lt;- rank(-stats)\n    ord &lt;- order(rnk)\n\n    statsAdj &lt;- stats[ord]\n\n    pathway.genes &lt;- unname(as.vector(na.omit(match(pathway.genes, names(statsAdj)))))\n    pathway.genes &lt;- sort(pathway.genes)\n    pathway.genes &lt;- unique(pathway.genes)\n\n    gene.ids &lt;- names(statsAdj[pathway.genes])\n    pd$ticks$gene &lt;- gene.ids\n    pd$ticks$color &lt;- tick.color\n\n    # Color by DE status if DE results are provided.\n    if (!is.null(dge.res)) {\n        if (id.term == \"rownames\") {\n            dge.res$ID &lt;- rownames(dge.res)\n        } else {\n            dge.res$ID &lt;- dge.res[[id.term]]\n        }\n\n        dge.res &lt;- dge.res[match(gene.ids, dge.res$ID), ]\n\n        # Get up and downregulated genes.\n        up &lt;- dge.res$ID[dge.res[[lfc.term]] &gt; lfc.thresh &amp; dge.res[[sig.term]] &lt; sig.thresh &amp; dge.res[[exp.term]] &gt; exp.thresh]\n        down &lt;- dge.res$ID[dge.res[[lfc.term]] &lt; -lfc.thresh &amp; dge.res[[sig.term]] &lt; sig.thresh &amp; dge.res[[exp.term]] &gt; exp.thresh]\n\n        # Color by DE status.\n        pd$ticks$color &lt;- ifelse(pd$ticks$gene %in% up, dge.up.color,\n            ifelse(pd$ticks$gene %in% down, dge.down.color, tick.color)\n        )\n    }\n\n    p &lt;- with(\n        pd,\n        ggplot(data = curve) +\n            geom_line(aes(x = rank, y = ES), color = \"green\") +\n            geom_segment(\n                data = ticks,\n                mapping = aes(\n                    x = rank, y = -spreadES / 16,\n                    xend = rank, yend = spreadES / 16,\n                    text = gene, color = color\n                ),\n                size = 0.2\n            ) +\n            scale_color_identity() +\n            geom_hline(yintercept = posES, colour = \"red\", linetype = \"dashed\") +\n            geom_hline(yintercept = negES, colour = \"red\", linetype = \"dashed\") +\n            geom_hline(yintercept = 0, colour = \"black\") +\n            theme(\n                panel.background = element_blank(),\n                panel.grid.major = element_line(color = \"grey92\")\n            ) +\n            labs(x = \"Rank\", y = \"Enrichment Score\", title = pathway.name)\n    )\n\n    # Add plot border, add ticks, set axis labels.\n    ay &lt;- list(\n        showline = TRUE,\n        mirror = TRUE,\n        linecolor = toRGB(\"black\"),\n        linewidth = 0.5,\n        showgrid = FALSE\n    )\n\n    ax &lt;- list(\n        showline = TRUE,\n        mirror = TRUE,\n        linecolor = toRGB(\"black\"),\n        linewidth = 0.5,\n        showgrid = FALSE\n    )\n\n    fig &lt;- ggplotly(p, tooltip = c(\"x\", \"text\")) %&gt;%\n        config(\n            edits = list(\n                annotationPosition = TRUE,\n                annotationTail = TRUE\n            ),\n            toImageButtonOptions = list(format = \"svg\"),\n            displaylogo = FALSE,\n            plotGlPixelRatio = 7\n        ) %&gt;%\n        layout(\n            showlegend = FALSE,\n            xaxis = ax,\n            yaxis = ay\n        )\n\n    # Feature count annotations.\n    if (!is.null(fgsea.res) &amp;&amp; plot.stats) {\n        padj &lt;- fgsea.res$padj[fgsea.res$pathway == pathway.name]\n        ES &lt;- fgsea.res$ES[fgsea.res$pathway == pathway.name]\n        NES &lt;- fgsea.res$NES[fgsea.res$pathway == pathway.name]\n        size &lt;- fgsea.res$size[fgsea.res$pathway == pathway.name]\n\n        if (ES &lt; 0) {\n            anno.x &lt;- 0\n            anno.y &lt;- 0.05\n        } else {\n            anno.x &lt;- 1\n            anno.y &lt;- 0.95\n        }\n\n        fig &lt;- fig %&gt;%\n            add_annotations(\n                x = anno.x,\n                y = anno.y,\n                xref = \"paper\",\n                yref = \"paper\",\n                text = paste0(\n                    \"padj: \", padj,\n                    \"\\nES: \", ES,\n                    \"\\nNES: \", NES,\n                    \"\\nGeneset Size: \", size\n                ),\n                showarrow = FALSE,\n                font = list(size = 10)\n            )\n    }\n\n    fig\n}\n\ngset &lt;- gs$GOBP_CANONICAL_WNT_SIGNALING_PATHWAY\nfgr &lt;- xl.lists$`ctx-K_5.v.W_5.C5.GO.BP`\nrg &lt;- ranked_lists$`ctx-K_5.v.W_5`\npw_name &lt;- \"GOBP_CANONICAL_WNT_SIGNALING_PATHWAY\"\n\np &lt;- plot_enrichment(gset, rg, pathway.name = pw_name, fgsea.res = fgr, plot.stats = TRUE)\n</code></pre>"},{"location":"Code_Snippets_Functions/#enrichmentover-representation-analyses","title":"Enrichment/Over-representation Analyses","text":"<p>These are kind of a pain to run for multiple comparisons, etc, so these functions try to ease that pain. Like a glass of water and handful of advil after a rough night.</p>"},{"location":"Code_Snippets_Functions/#kegg-enrichment","title":"KEGG Enrichment","text":"<pre><code>library(\"org.Mm.eg.db\")\nlibrary(\"org.Hs.eg.db\")\nlibrary(\"clusterProfiler\")\nlibrary(\"enrichplot\")\nlibrary(\"ggplot2\")\nlibrary(\"stringi\")\nlibrary(\"pathview\")\nlibrary(\"ReactomePA\")\n\n#' @param res.list Named list of DESeq2 results data.frames.\n#' @param padj.th Numeric scalar to use as significance threshold for DE genes.\n#' @param lfc.th Numeric scalar to use as log fold change threshold for DE genes.\n#' @param outdir Character scalar for output directory.\n#' @param OrgDb Character scalar for annotation database to use.\n#' @param id.col Character scalar indicating name of gene ID column for each data.frame in \\code{res.list}\n#' @param id.type Character scalar indicating type of gene ID used. See \\code{keytypes(org.Hs.eg.db)} for all options.\n#' @param organism Character scalar indicating species in KEGG format (\"hsa\", \"mmu\", etc).\n#' @param ... Passed to \\code{compareCluster}.\n#' @author Jared Andrews\nrun_enrichKEGG &lt;- function(res.list, padj.th = 0.05, lfc.th = 0, outdir = \"./enrichments\",\n                         OrgDb = \"org.Hs.eg.db\", id.col = \"ENSEMBL\", id.type = \"ENSEMBL\", \n                         organism = \"hsa\", ...) {\n  # Do GO enrichment on up/downregulated genes.\n  for (r in names(res.list)) {\n    df &lt;- res.list[[r]]\n\n    if (lfc.th != 0) {\n      r &lt;- paste0(r,\"-LFC\", round(lfc.th, digits = 3), \"filt\")\n    }\n\n    out &lt;- file.path(outdir, r)\n    dir.create(paste0(out, \"/KEGG_pathview\"), showWarnings = FALSE, recursive = TRUE)\n\n    # Strip gene version info if ensembl.\n    if (id.type == \"ENSEMBL\") {\n      xx &lt;- strsplit(df[[id.col]], \"\\\\.\")\n      df[[id.col]] &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n    }\n\n    # Get FC values for pathway plots.\n    df &lt;- df[!is.na(df$padj),]\n    geneList &lt;- bitr(df[[id.col]], fromType = id.type, toType = \"ENTREZID\", \n                      OrgDb = OrgDb)\n    geneList$FC &lt;- df$log2FoldChange[match(geneList$ENSEMBL, df$ENSEMBL)]\n    gl &lt;- geneList$FC\n    names(gl) &lt;- geneList$ENTREZID\n    gl = sort(gl, decreasing = TRUE)\n\n    # Get gene categories.\n    genes &lt;- list(upregulated = df[[id.col]][df$padj &lt; padj.th &amp; df$log2FoldChange &gt; lfc.th],\n                  downregulated = df[[id.col]][df$padj &lt; padj.th &amp; df$log2FoldChange &lt; -lfc.th],\n                  all_de = df[[id.col]][df$padj &lt; padj.th])\n\n    skip &lt;- FALSE\n\n    tryCatch({\n      genes$upregulated &lt;- bitr(genes$upregulated, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n\n      genes$downregulated &lt;- bitr(genes$downregulated, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n\n      genes$all_de &lt;- bitr(genes$all_de, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n    }, \n    error = function(e) {\n      message(\"There was an error: \", e)\n      message(\"Most likely, no gene identifiers for hits could be mapped to entrez IDs.\")\n      message(\"Proceeding to next comparison in results list.\")\n      skip &lt;&lt;- TRUE\n    })\n\n    if (skip) {\n      next\n    }\n\n    # Remove lowly expressed genes.\n    bg &lt;- df[[id.col]][!is.na(df$padj)]\n    bg &lt;- bitr(bg, fromType = id.type, toType = \"ENTREZID\", OrgDb = OrgDb)$ENTREZID\n\n    ck &lt;- compareCluster(geneCluster = genes, fun = enrichKEGG, keyType = \"kegg\", universe = bg, organism = organism, ...)\n    if (!is.null(ck)) {\n      ck &lt;- setReadable(ck, OrgDb = OrgDb, keyType=\"ENTREZID\")\n\n      # Term similarities via Jaccard Similarity index.\n      ego &lt;- pairwise_termsim(ck)\n\n      height = 4 + (0.015 * length(ego@compareClusterResult$Cluster))\n\n      pdf(paste0(out, \"/KEGG_Enrichments.Top20_perGroup.pdf\"), width = 6, height = height)\n      p &lt;- dotplot(ego, showCategory = 20, font.size = 7)\n      print(p)\n      p &lt;- dotplot(ego, size = \"count\", showCategory = 20, font.size = 7)\n      print(p)\n      dev.off()\n\n      pdf(paste0(out, \"/KEGG_Enrichments.termsim.Top20_perGroup.pdf\"), width = 9, height = 9)\n      p &lt;- emapplot(ego, pie=\"count\", cex_category=0.9, cex_label_category = 0.9, \n                    layout=\"kk\", repel = TRUE, showCategory = 20)\n      print(p)\n      dev.off()\n\n      for (x in ego@compareClusterResult$ID) {\n        pname &lt;- ego@compareClusterResult$Description[ego@compareClusterResult$ID == x]\n        xx &lt;- tryCatch(\n          pathview(gene.data  = gl,\n                   pathway.id = x,\n                   kegg.dir = paste0(out, \"/KEGG_pathview/\"),\n                   species    = organism,\n                   out.suffix = pname,\n                   limit      = list(gene=3, cpd=1),\n                   kegg.native = TRUE),\n          error = function(e) {\"bah\"}\n        )\n\n        graphics.off()\n      }\n\n      # This idiotic workaround copies the PNGs to our wanted directory as pathview generates\n      # all output in the working directory with no way to alter output location. Pretty dumb.\n      old_dir &lt;- \"./\"\n      new_dir &lt;- paste0(out, \"/KEGG_pathview/\")\n      old_files &lt;- list.files(path = old_dir, pattern = \"png\", full.names = T)\n      new_files &lt;- sub(old_dir, new_dir, old_files)\n      file.rename(from = old_files, to = new_files)\n\n      saveRDS(ego, file = paste0(out, \"/enrichKEGG.results.RDS\"))\n      ego &lt;- as.data.frame(ego)\n      write.table(ego, file = paste0(out, \"/enrichKEGG.results.txt\"), sep = \"\\t\", row.names = FALSE, quote = FALSE)\n    }\n  }\n}\n\nrun_enrichKEGG(res, OrgDb = \"org.Mm.eg.db\", organism = \"mmu\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#reactome-enrichment","title":"Reactome Enrichment","text":"<pre><code>#' @param res.list Named list of DESeq2 results data.frames.\n#' @param padj.th Numeric scalar to use as significance threshold for DE genes.\n#' @param lfc.th Numeric scalar to use as log fold change threshold for DE genes.\n#' @param outdir Character scalar for output directory.\n#' @param OrgDb Character scalar for annotation database to use.\n#' @param id.col Character scalar indicating name of gene ID column for each data.frame in \\code{res.list}\n#' @param id.type Character scalar indicating type of gene ID used. See \\code{keytypes(org.Hs.eg.db)} for all options.\n#' @param organism Character scalar indicating ReactomePA-supported species (\"human\", \"mouse\").\n#' @param ... Passed to \\code{compareCluster}.\n#' @author Jared Andrews\nrun_enrichPathway &lt;- function(res.list, padj.th = 0.05, lfc.th = 0, outdir = \"./enrichments\",\n                         OrgDb = \"org.Hs.eg.db\", id.col = \"ENSEMBL\", id.type = \"ENSEMBL\", organism = \"human\", ...) {\n  # Do GO enrichment on up/downregulated genes.\n  for (r in names(res.list)) {\n    df &lt;- res.list[[r]]\n\n    if (lfc.th != 0) {\n      r &lt;- paste0(r,\"-LFC\", round(lfc.th, digits = 3), \"filt\")\n    }\n\n    out &lt;- file.path(outdir, r)\n    dir.create(paste0(out, \"/Reactome_pathways\"), showWarnings = FALSE, recursive = TRUE)\n\n    # Strip gene version info if ensembl.\n    if (id.type == \"ENSEMBL\") {\n      xx &lt;- strsplit(df[[id.col]], \"\\\\.\")\n      df[[id.col]] &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n    }\n\n    # Get FC values for pathway plots.\n    df &lt;- df[!is.na(df$padj),]\n    geneList &lt;- bitr(df[[id.col]], fromType = id.type, toType = \"ENTREZID\", \n                      OrgDb = OrgDb)\n    geneList$FC &lt;- df$log2FoldChange[match(geneList$ENSEMBL, df$ENSEMBL)]\n    gl &lt;- geneList$FC\n    names(gl) &lt;- geneList$ENTREZID\n    gl = sort(gl, decreasing = TRUE)\n\n    genes &lt;- list(upregulated = df[[id.col]][df$padj &lt; padj.th &amp; df$log2FoldChange &gt; lfc.th],\n                  downregulated = df[[id.col]][df$padj &lt; padj.th  &amp; df$log2FoldChange &lt; -lfc.th],\n                  all_de = df[[id.col]][df$padj &lt; padj.th])\n\n    skip &lt;- FALSE\n\n    tryCatch({\n      genes$upregulated &lt;- bitr(genes$upregulated, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n\n      genes$downregulated &lt;- bitr(genes$downregulated, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n\n      genes$all_de &lt;- bitr(genes$all_de, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n    }, \n    error = function(e) {\n      message(\"There was an error: \", e)\n      message(\"Most likely, no gene identifiers for hits could be mapped to entrez IDs.\")\n      message(\"Proceeding to next comparison in results list.\")\n      skip &lt;&lt;- TRUE\n    })\n\n    if (skip) {\n      next\n    }\n\n    # Remove duplicate IDs.\n    gl &lt;- gl[unique(names(gl))]\n\n    # Remove lowly expressed genes.\n    bg &lt;- df[[id.col]][!is.na(df$padj)]\n    bg &lt;- bitr(bg, fromType = id.type, toType = \"ENTREZID\", OrgDb = OrgDb)$ENTREZID\n\n    ck &lt;- compareCluster(geneCluster = genes, fun = enrichPathway, universe = bg, \n                         readable = TRUE, organism = organism, ...)\n    if (!is.null(ck)) {\n      # Term similarities via Jaccard Similarity index.\n      ego &lt;- pairwise_termsim(ck)\n\n      # Adjust plot height based on number of terms.\n      height = 4 + (0.015 * length(ego@compareClusterResult$Cluster))\n\n      pdf(paste0(out, \"/Reactome_Enrichments.Top20_perGroup.pdf\"), width = 6, height = height)\n      p &lt;- dotplot(ego, showCategory = 20, font.size = 7)\n      print(p)\n      p &lt;- dotplot(ego, size = \"count\", showCategory = 20, font.size = 7)\n      print(p)\n      dev.off()\n\n      pdf(paste0(out, \"/Reactome_Enrichments.termsim.Top20_perGroup.pdf\"), width = 9, height = 9)\n      p &lt;- emapplot(ego, pie=\"count\", cex_category=0.9, cex_label_category = 0.9, \n                    layout=\"kk\", repel = TRUE, showCategory = 20)\n      print(p)\n      dev.off()\n\n      if (nrow(ego) &gt; 2) {\n        pdf(paste0(out, \"/Reactome_Enrichments.termsim.Top30_Tree.pdf\"), width = 17, height = 14)\n        p &lt;- treeplot(ego, showCategory = 30, fontsize = 4, offset.params = list(bar_tree = rel(2.5), tiplab = rel(2.5), extend = 0.3, hexpand = 0.1), cluster.params = list(method = \"ward.D\", n = min(c(6, ceiling(sqrt(nrow(ego))))), color = NULL, label_words_n = 5, label_format = 30))\n        print(p)\n        dev.off()\n\n        pdf(paste0(out, \"/Reactome_Enrichments.termsim.Top10_FullNet.pdf\"), width = 15, height = 15)\n        p &lt;- cnetplot(ego, showCategory = 10, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n        print(p)\n        dev.off()\n\n        pdf(paste0(out, \"/Reactome_Enrichments.termsim.Top5_FullNet.pdf\"), width = 12, height = 12)\n        p &lt;- cnetplot(ego, showCategory = 5, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n        print(p)\n        dev.off()\n      }\n\n      saveRDS(ego, file = paste0(out, \"/enrichPathway.reactome.RDS\"))\n      ego &lt;- as.data.frame(ego)\n      write.table(ego, file = paste0(out, \"/enrichPathway.reactome.results.txt\"), \n                  sep = \"\\t\", row.names = FALSE, quote = FALSE)\n    }\n  }\n}\n\nrun_enrichPathway(res, OrgDb = \"org.Mm.eg.db\", organism = \"mouse\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#go-enrichment","title":"GO Enrichment","text":"<pre><code>#' @param res.list Named list of DESeq2 results data.frames.\n#' @param padj.th Numeric scalar to use as significance threshold for DE genes.\n#' @param lfc.th Numeric scalar to use as log fold change threshold for DE genes.\n#' @param outdir Character scalar for output directory.\n#' @param OrgDb Character scalar for annotation database to use.\n#' @param id.col Character scalar indicating name of gene ID column for each data.frame in \\code{res.list}\n#' @param id.type Character scalar indicating type of gene ID used. See \\code{keytypes(org.Hs.eg.db)} for all options.\n#' @param onts Character vector indicating ontologies to test individually. \n#'   Options must be one or more of \"ALL\", \"BP\", \"CC\", or \"MF\". \n#'   Default uses all of those options. \n#' @param ... Passed to \\code{compareCluster}\n#' @author Jared Andrews\nrun_enrichGO &lt;- function(res.list, padj.th = 0.05, lfc.th = 0, outdir = \"./enrichments\",\n                         OrgDb = \"org.Hs.eg.db\", id.col = \"ENSEMBL\", id.type = \"ENSEMBL\", \n                         onts = c(\"BP\", \"MF\", \"CC\", \"ALL\"), ...) {\n  # Do GO enrichment on up/downregulated genes.\n  for (r in names(res.list)) {\n    df &lt;- res.list[[r]]\n\n    if (lfc.th != 0) {\n      r &lt;- paste0(r,\"-LFC\", round(lfc.th, digits = 3), \"filt\")\n    }\n\n    out &lt;- file.path(outdir, r)\n    dir.create(paste0(out, \"/GO_enrichments\"), showWarnings = FALSE, recursive = TRUE)\n\n    # Strip gene version info if ensembl.\n    if (id.type == \"ENSEMBL\") {\n      xx &lt;- strsplit(df[[id.col]], \"\\\\.\")\n      df[[id.col]] &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n    }\n\n    # Get FC values for pathway plots.\n    df &lt;- df[!is.na(df$padj),]\n    geneList &lt;- bitr(df[[id.col]], fromType = id.type, toType = \"ENTREZID\", \n                      OrgDb = OrgDb)\n    geneList$FC &lt;- df$log2FoldChange[match(geneList$ENSEMBL, df$ENSEMBL)]\n    gl &lt;- geneList$FC\n    names(gl) &lt;- geneList$ENTREZID\n    gl &lt;- sort(gl, decreasing = TRUE)\n    # Remove duplicate IDs.\n    gl &lt;- gl[unique(names(gl))]\n\n    genes &lt;- list(upregulated = df[[id.col]][df$padj &lt; padj.th &amp; df$log2FoldChange &gt; lfc.th],\n                  downregulated = df[[id.col]][df$padj &lt; padj.th  &amp; df$log2FoldChange &lt; -lfc.th],\n                  all_de = df[[id.col]][df$padj &lt; padj.th])\n\n    skip &lt;- FALSE\n\n    tryCatch({\n      genes$upregulated &lt;- bitr(genes$upregulated, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n\n      genes$downregulated &lt;- bitr(genes$downregulated, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n\n      genes$all_de &lt;- bitr(genes$all_de, fromType = id.type, toType = \"ENTREZID\", \n                            OrgDb = OrgDb)$ENTREZID\n    }, \n    error = function(e) {\n      message(\"There was an error: \", e)\n      message(\"Most likely, no gene identifiers for hits could be mapped to entrez IDs.\")\n      message(\"Proceeding to next comparison in results list.\")\n      skip &lt;&lt;- TRUE\n    })\n\n    if (skip) {\n      next\n    }\n\n    # Remove lowly expressed genes.\n    bg &lt;- df[[id.col]][!is.na(df$padj)]\n    bg &lt;- bitr(bg, fromType = id.type, toType = \"ENTREZID\", OrgDb = OrgDb)$ENTREZID\n\n    for (ont in onts) {\n\n      ck &lt;- compareCluster(geneCluster = genes, fun = enrichGO, universe = bg, \n                           readable = TRUE, ont = ont, OrgDb = OrgDb, ...)\n\n      if (!is.null(ck)) {\n        # Term similarities via Jaccard Similarity index.\n        ego &lt;- pairwise_termsim(ck)\n\n        # Adjust plot height based on number of terms.\n        height = 3.75 + (0.025 * length(ego@compareClusterResult$Cluster))\n\n        pdf(paste0(out, \"/GO_Enrichments.Top20_perGroup.\", ont, \".pdf\"), width = 6, height = height)\n        p &lt;- dotplot(ego, showCategory = 20, font.size = 7)\n        print(p)\n        p &lt;- dotplot(ego, size = \"count\", showCategory = 20, font.size = 7)\n        print(p)\n        dev.off()\n\n        pdf(paste0(out, \"/GO_Enrichments.termsim.Top20_perGroup.\", ont, \".pdf\"), width = 9, height = 9)\n        p &lt;- emapplot(ego, pie=\"count\", cex_category=0.9, cex_label_category = 0.9,\n                      layout=\"kk\", repel = TRUE, showCategory = 20)\n        print(p)\n        dev.off()\n\n\n        if (nrow(ego) &gt; 2) {\n          pdf(paste0(out, \"/GO_Enrichments.termsim.Top30_Tree.\", ont, \".pdf\"), width = 17, height = 14)\n          p &lt;- treeplot(ego, showCategory = 30, fontsize = 4, offset.params = list(bar_tree = rel(2.5), tiplab = rel(2.5), extend = 0.3, hexpand = 0.1), cluster.params = list(method = \"ward.D\", n = min(c(6, ceiling(sqrt(nrow(ego))))), color = NULL, label_words_n = 5, label_format = 30))\n          print(p)\n          dev.off()\n\n          pdf(paste0(out, \"/GO_Enrichments.termsim.Top10_FullNet.\", ont, \".pdf\"), width = 15, height = 15)\n          p &lt;- cnetplot(ego, showCategory = 10, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n          print(p)\n          dev.off()\n\n          pdf(paste0(out, \"/GO_Enrichments.termsim.Top5_FullNet.\", ont, \".pdf\"), width = 13, height = 13)\n          p &lt;- cnetplot(ego, showCategory = 5, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n          print(p)\n          dev.off()\n        }\n\n        saveRDS(ego, file = paste0(out, \"/enrichGO.\", ont, \".RDS\"))\n        ego &lt;- as.data.frame(ego)\n        write.table(ego, file = paste0(out, \"/enrichGO.results.\", ont, \".txt\"), \n                    sep = \"\\t\", row.names = FALSE, quote = FALSE)\n      }\n    }\n  }\n}\n\nrun_enrichGO(res, OrgDb = \"org.Mm.eg.db\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#keggreactome-enrichment-simple","title":"KEGG/Reactome Enrichment (simple)","text":"<p>This version just uses lists of genes that can be defined however which way.</p> <pre><code>library(\"org.Mm.eg.db\")\nlibrary(\"org.Hs.eg.db\")\nlibrary(\"clusterProfiler\")\nlibrary(\"enrichplot\")\nlibrary(\"ggplot2\")\nlibrary(\"stringi\")\nlibrary(\"pathview\")\nlibrary(\"ReactomePA\")\n\n#' @param genes Character vector of gene IDs to test for enrichment.\n#' @param bg Character vector of gene IDs to be used as background.\n#' @param name Character scalar for output name.\n#' @param outdir Character scalar for output directory.\n#' @param OrgDb Character scalar for annotation database to use.\n#' @param id.type Character scalar indicating type of gene ID used. See \\code{keytypes(org.Hs.eg.db)} for all options.\n#' @param kegg.organism Character scalar indicating species in KEGG format (\"hsa\", \"mmu\", etc).\n#' @param reactome.organism Character scalar indicating species in Reactome format (\"human\", \"mouse\", etc).\n#' @param fun Character scalar indicating which \"enrich\" function to run (\"enrichKEGG\", \"enrichPathway\").\n#' @param ... Passed to specified enrichments function.\n#' @author Jared Andrews\nrun_enrich_simple &lt;- function(genes, bg, name = \"sample\", outdir = \"./enrichments\",\n                         OrgDb = \"org.Hs.eg.db\", id.type = \"ENSEMBL\", \n                         kegg.organism = \"hsa\", reactome.organism = \"human\", fun = \"enrichKEGG\", ...) {\n\n  out &lt;- file.path(outdir, name)\n  dir.create(out, recursive = TRUE, showWarnings = FALSE)\n\n  # Strip gene version info if ensembl.\n  if (id.type == \"ENSEMBL\") {\n    xx &lt;- strsplit(genes, \"\\\\.\")\n    genes &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n\n    xx &lt;- strsplit(bg, \"\\\\.\")\n    bg &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n  }\n\n  skip &lt;- FALSE\n\n  tryCatch({\n    genes &lt;- bitr(genes, fromType = id.type, toType = \"ENTREZID\", \n                          OrgDb = OrgDb)$ENTREZID\n  }, \n  error = function(e) {\n    message(\"There was an error: \", e)\n    message(\"Most likely, no gene identifiers for hits could be mapped to entrez IDs.\")\n    skip &lt;&lt;- TRUE\n  })\n\n  if (skip) {\n    next\n  }\n\n  bg &lt;- bitr(bg, fromType = id.type, toType = \"ENTREZID\", OrgDb = OrgDb)$ENTREZID\n\n  if (fun == \"enrichKEGG\") {\n    ego &lt;- enrichKEGG(gene = genes, universe = bg, organism = kegg.organism, ...)\n  } else if (fun == \"enrichPathway\") {\n    ego &lt;- enrichPathway(gene = genes, universe = bg, organism = reactome.organism, ...)\n  } \n\n  if (nrow(as.data.frame(ego)) &gt; 0) {\n    # Term similarities via Jaccard Similarity index.\n    ego &lt;- pairwise_termsim(ego)\n    ego &lt;- setReadable(ego, OrgDb = OrgDb, keyType=\"ENTREZID\")\n    pdf(paste0(out, \"/\", fun, \".Top30.pdf\"), width = 6, height = 8)\n    p &lt;- dotplot(ego, showCategory = 30, font.size = 7)\n    print(p)\n    p &lt;- barplot(ego, showCategory = 30, font.size = 7)\n    print(p)\n    dev.off()\n\n    if (nrow(as.data.frame(ego)) &gt; 2) {\n      pdf(paste0(out, \"/\", fun, \".termsim.Top30_Tree.pdf\"), width = 17, height = 14)\n      p &lt;- treeplot(ego, showCategory = 30, fontsize = 4, offset.params = list(bar_tree = rel(2.5), tiplab = rel(2.5), extend = 0.3, hexpand = 0.1), cluster.params = list(method = \"ward.D\", n = min(c(6, ceiling(sqrt(nrow(ego))))), color = NULL, label_words_n = 5, label_format = 30))\n      print(p)\n      dev.off()\n\n      pdf(paste0(out, \"/\", fun, \".termsim.Top10_FullNet.pdf\"), width = 15, height = 15)\n      p &lt;- cnetplot(ego, showCategory = 10, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n      print(p)\n      dev.off()\n\n      pdf(paste0(out, \"/\", fun, \".termsim.Top5_FullNet.pdf\"), width = 12, height = 12)\n      p &lt;- cnetplot(ego, showCategory = 5, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n      print(p)\n      dev.off()\n    }\n\n    saveRDS(ego, file = paste0(out, \"/\", fun, \".results.RDS\"))\n    ego &lt;- as.data.frame(ego)\n    write.table(ego, file = paste0(out, \"/\", fun, \".results.txt\"), sep = \"\\t\", row.names = FALSE, quote = FALSE)\n  }\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#go-enrichment-simple","title":"GO Enrichment (simple)","text":"<p>This version just uses lists of genes that can be defined however which way.</p> <pre><code>#' @param genes Character vector of gene IDs to test for enrichment.\n#' @param bg Character vector of gene IDs to be used as background.\n#' @param name Character scalar for output name.\n#' @param outdir Character scalar for output directory.\n#' @param OrgDb Character scalar for annotation database to use.\n#' @param id.type Character scalar indicating type of gene ID used. See \\code{keytypes(org.Hs.eg.db)} for all options.\n#' @param onts Character vector indicating ontologies to test individually. \n#'   Options must be one or more of \"ALL\", \"BP\", \"CC\", or \"MF\". \n#'   Default uses all of those options. \n#' @param ... Passed to specified enrichments function.\n#' @author Jared Andrews\nrun_enrichGO_simple &lt;- function(genes, bg, name = \"sample\", outdir = \"./enrichments\",\n                         OrgDb = \"org.Hs.eg.db\", id.type = \"ENSEMBL\", onts = c(\"BP\", \"MF\", \"CC\", \"ALL\"), ...) {\n\n  out &lt;- file.path(outdir, name)\n  dir.create(out, recursive = TRUE, showWarnings = FALSE)\n\n  # Strip gene version info if ensembl.\n  if (id.type == \"ENSEMBL\") {\n    xx &lt;- strsplit(genes, \"\\\\.\")\n    genes &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n\n    xx &lt;- strsplit(bg, \"\\\\.\")\n    bg &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n  }\n\n  skip &lt;- FALSE\n\n  tryCatch({\n    genes &lt;- bitr(genes, fromType = id.type, toType = \"ENTREZID\", \n                          OrgDb = OrgDb)$ENTREZID\n\n  }, \n  error = function(e) {\n    message(\"There was an error: \", e)\n    message(\"Most likely, no gene identifiers for hits could be mapped to entrez IDs.\")\n    skip &lt;&lt;- TRUE\n  })\n\n  if (skip) {\n    next\n  }\n\n  bg &lt;- bitr(bg, fromType = id.type, toType = \"ENTREZID\", OrgDb = OrgDb)$ENTREZID\n\n  for (ont in onts) {\n    ego &lt;- enrichGO(genes, OrgDb = OrgDb, universe = bg, ont = ont, readable = TRUE, ...)\n\n    if (nrow(as.data.frame(ego)) &gt; 0) {\n      # Term similarities via Jaccard Similarity index.\n      ego &lt;- pairwise_termsim(ego)\n      pdf(paste0(out, \"/enrichGO.\", ont, \".Top30.pdf\"), width = 6, height = 8)\n      p &lt;- dotplot(ego, showCategory = 30, font.size = 7)\n      print(p)\n      p &lt;- barplot(ego, showCategory = 30, font.size = 7)\n      print(p)\n      dev.off()\n\n      if (nrow(as.data.frame(ego)) &gt; 2) {\n        pdf(paste0(out, \"/enrichGO.\", ont, \".termsim.Top30_Tree.pdf\"), width = 17, height = 14)\n        p &lt;- treeplot(ego, showCategory = 30, fontsize = 4, offset.params = list(bar_tree = rel(2.5), tiplab = rel(2.5), extend = 0.3, hexpand = 0.1), cluster.params = list(method = \"ward.D\", n = min(c(6, ceiling(sqrt(nrow(ego))))), color = NULL, label_words_n = 5, label_format = 30))\n        print(p)\n        dev.off()\n\n        pdf(paste0(out, \"/enrichGO.\", ont, \".termsim.Top10_FullNet.pdf\"), width = 15, height = 15)\n        p &lt;- cnetplot(ego, showCategory = 10, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n        print(p)\n        dev.off()\n\n        pdf(paste0(out, \"/enrichGO.\", ont, \".termsim.Top5_FullNet.pdf\"), width = 12, height = 12)\n        p &lt;- cnetplot(ego, showCategory = 5, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n        print(p)\n        dev.off()\n      }\n\n      saveRDS(ego, file = paste0(out, \"/enrichGO.\", ont, \".results.RDS\"))\n      ego &lt;- as.data.frame(ego)\n      write.table(ego, file = paste0(out, \"/enrichGO.\", ont, \".results.txt\"), sep = \"\\t\", row.names = FALSE, quote = FALSE)\n    }\n  }\n}\n\nrezzies &lt;- c(\"K_0.v.W_0-b_cul\", \"K_1.v.W_1-b_cul\", \"K_2.v.W_2-b_cul\", \"K_5.v.W_5-b_cul\", \"K_7.v.W_7-b_cul\")\nbgs &lt;- list(bg0 = res$`K_0.v.W_0-b_cul`$SYMBOL[!is.na(res$`K_0.v.W_0-b_cul`$padj)],\n  bg1 = res$`K_1.v.W_1-b_cul`$SYMBOL[!is.na(res$`K_1.v.W_1-b_cul`$padj)],\n  bg2 = res$`K_2.v.W_2-b_cul`$SYMBOL[!is.na(res$`K_2.v.W_2-b_cul`$padj)],\n  bg5 = res$`K_5.v.W_5-b_cul`$SYMBOL[!is.na(res$`K_5.v.W_5-b_cul`$padj)],\n  bg7 = res$`K_7.v.W_7-b_cul`$SYMBOL[!is.na(res$`K_7.v.W_7-b_cul`$padj)])\n\nfor (i in seq_along(df_lists)) {\n  n &lt;- names(df_lists)[i]\n  bg &lt;- ifelse(grepl(\"0d\", n), \"bg0\", \n               ifelse(grepl(\"1d\", n), \"bg1\",\n               ifelse(grepl(\"2d\", n), \"bg2\",\n               ifelse(grepl(\"5d\", n), \"bg5\",\n               ifelse(grepl(\"7d\", n), \"bg7\")))))\n  g &lt;- df_lists[[i]]\n\n  run_enrich_simple(g, bg = bgs[[bg]], OrgDb = \"org.Mm.eg.db\", kegg.organism = \"mmu\", reactome.organism = \"mouse\", id.type = \"SYMBOL\", outdir = \"./eed_comparison/enrichments\", name = n, fun = \"enrichKEGG\")\n\n  run_enrich_simple(g, bg = bgs[[bg]], OrgDb = \"org.Mm.eg.db\", kegg.organism = \"mmu\", reactome.organism = \"mouse\", id.type = \"SYMBOL\", outdir = \"./eed_comparison/enrichments\", name = n, fun = \"enrichPathway\")\n\n  run_enrichGO_simple(g, bg = bgs[[bg]], OrgDb = \"org.Mm.eg.db\", id.type = \"SYMBOL\", outdir = \"./eed_comparison/enrichments\", name = n)\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#hypergeometric-testing","title":"Hypergeometric Testing","text":"<p>Of arbitrary genesets. Useful for custom lists.</p> <pre><code>#' Hypergeometric testing with arbitrary gene sets\n#'\n#' @param genes Character vector of gene IDs to test for enrichment.\n#' @param bg Character vector of gene IDs to be used as background.\n#' @param TERM2GENE data.frame of two columns, the first for the term and the second for the gene ID.\n#'   Each gene in each geneset gets its own row (long format). Gene identifiers should be ENTREZID.\n#' @param name Character scalar for output name.\n#' @param gsname Name of collection of genesets, used for output file naming.\n#' @param outdir Character scalar for output directory.\n#' @param OrgDb Character scalar for annotation database to use.\n#' @param id.type Character scalar indicating type of gene ID used. See \\code{keytypes(org.Hs.eg.db)} for all options.\n#' @param ... Passed to specified enrichments function.\n#' @author Jared Andrews\nrun_enrich_universal &lt;- function(genes, bg, TERM2GENE, name = \"sample\", gsname = \"custom\", outdir = \"./enrichments\",\n                         OrgDb = \"org.Hs.eg.db\", id.type = \"ENSEMBL\", ...) {\n\n  out &lt;- file.path(outdir, name)\n  dir.create(out, recursive = TRUE, showWarnings = FALSE)\n\n  # Strip gene version info if ensembl.\n  if (id.type == \"ENSEMBL\") {\n    xx &lt;- strsplit(genes, \"\\\\.\")\n    genes &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n\n    xx &lt;- strsplit(bg, \"\\\\.\")\n    bg &lt;- unlist(lapply(xx, FUN = function(x) x[1]))\n  }\n\n  skip &lt;- FALSE\n\n  tryCatch({\n    genes &lt;- bitr(genes, fromType = id.type, toType = \"ENTREZID\",\n                          OrgDb = OrgDb)$ENTREZID\n  },\n  error = function(e) {\n    message(\"There was an error: \", e)\n    message(\"Most likely, no gene identifiers for hits could be mapped to entrez IDs.\")\n    skip &lt;&lt;- TRUE\n  })\n\n  if (skip) {\n    next\n  }\n\n  ego &lt;- enricher(gene = genes, universe = bg, TERM2GENE = TERM2GENE, ...)\n\n  if (nrow(as.data.frame(ego)) &gt; 0) {\n    # Term similarities via Jaccard Similarity index.\n    ego &lt;- pairwise_termsim(ego)\n    # ego &lt;- setReadable(ego, OrgDb = OrgDb, keyType=\"ENTREZID\")\n    pdf(paste0(out, \"/\", gsname, \".Top30.pdf\"), width = 6, height = 8)\n    p &lt;- dotplot(ego, showCategory = 30, font.size = 7)\n    print(p)\n    p &lt;- barplot(ego, showCategory = 30, font.size = 7)\n    print(p)\n    dev.off()\n\n    if (nrow(as.data.frame(ego)) &gt; 2) {\n      pdf(paste0(out, \"/\", gsname, \".termsim.Top30_Tree.pdf\"), width = 17, height = 14)\n      p &lt;- treeplot(ego, showCategory = 30, fontsize = 4, offset.params = list(bar_tree = rel(2.5), tiplab = rel(2.5), extend = 0.3, hexpand = 0.1), cluster.params = list(method = \"ward.D\", n = min(c(6, ceiling(sqrt(nrow(ego))))), color = NULL, label_words_n = 5, label_format = 30))\n      print(p)\n      dev.off()\n\n      pdf(paste0(out, \"/\", gsname, \".termsim.Top10_FullNet.pdf\"), width = 15, height = 15)\n      p &lt;- cnetplot(ego, showCategory = 10, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n      print(p)\n      dev.off()\n\n      pdf(paste0(out, \"/\", gsname, \".termsim.Top5_FullNet.pdf\"), width = 12, height = 12)\n      p &lt;- cnetplot(ego, showCategory = 5, cex.params = list(category_label = 1.3, gene_label = 0.9, category_node = 1, gene_node = 1), layout = \"kk\")\n      print(p)\n      dev.off()\n    }\n\n    saveRDS(ego, file = paste0(out, \"/\", gsname, \".results.RDS\"))\n    ego &lt;- as.data.frame(ego)\n    write.table(ego, file = paste0(out, \"/\", gsname, \".results.txt\"), sep = \"\\t\", row.names = FALSE, quote = FALSE)\n  }\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#get-all-gene-ids-for-go-terms-associated-with-a-given-search-term","title":"Get All Gene IDs for GO Terms Associated with a Given Search Term","text":"<pre><code>#' Retrieve Genes Associated with GO Terms Containing a Specific Search Term\n#'\n#' This function searches for Gene Ontology (GO) Biological Process terms that contain a specified search term\n#' and retrieves all associated genes for the specified species and ID type.\n#'\n#' @param search_term A character string specifying the term to search for within GO Biological Process terms (case-insensitive).\n#' @param species A character string specifying the species. Supported species include \"human\", \"mouse\", and \"rat\".\n#'                Default is \"human\".\n#' @param id_type A character string specifying the type of gene identifier to return.\n#'                Options include \"SYMBOL\", \"ENTREZID\", and \"ENSEMBL\". Default is \"SYMBOL\".\n#'\n#' @return A named character vector of gene identifiers of the specified type associated with GO terms that contain the search term.\n#'         The names of the vector are the corresponding Entrez Gene IDs (if `id_type` is not \"ENTREZID\").\n#'\n#' @details\n#' The function performs the following steps:\n#' \\enumerate{\n#'   \\item Retrieves all GO terms and their descriptions.\n#'   \\item Searches for GO terms that include the specified search term.\n#'   \\item Retrieves all Entrez Gene IDs associated with the matching GO terms.\n#'   \\item Maps Entrez Gene IDs to the specified type of gene identifier.\n#' }\n#'\n#' **Note:** The function supports species specified in the `species_packages` list. For other organisms, you can add the appropriate entries.\n#'\n#' @examples\n#' \\dontrun{\n#' # Retrieve human gene symbols associated with GO terms containing \"WNT\"\n#' genes_wnt_human &lt;- get_genes_by_go_term(\"WNT\", species = \"human\", id_type = \"SYMBOL\")\n#' print(genes_wnt_human)\n#'\n#' # Retrieve mouse Ensembl IDs associated with GO terms containing \"apoptosis\"\n#' genes_apoptosis_mouse &lt;- get_genes_by_go_term(\"apoptosis\", species = \"mouse\", id_type = \"ENSEMBL\")\n#' print(genes_apoptosis_mouse)\n#'\n#' # Retrieve rat Entrez IDs associated with GO terms containing \"cell cycle\"\n#' genes_cell_cycle_rat &lt;- get_genes_by_go_term(\"cell cycle\", species = \"rat\", id_type = \"ENTREZID\")\n#' print(genes_cell_cycle_rat)\n#' }\n#'\n#' @importFrom AnnotationDbi mapIds\n#' @import GO.db\n#' @import org.Hs.eg.db\n#' @import org.Mm.eg.db\n#' @import org.Rn.eg.db\n#' @export\nget_genes_by_go_term &lt;- function(search_term, species = \"human\", id_type = \"SYMBOL\") {\n\n  # Map species to organism package names\n  species_packages &lt;- list(\n    \"human\" = \"org.Hs.eg.db\",\n    \"mouse\" = \"org.Mm.eg.db\",\n    \"rat\" = \"org.Rn.eg.db\"\n    # Add more species as needed\n  )\n\n  if (!species %in% names(species_packages)) {\n    stop(\"Unsupported species. Please use one of: \", paste(names(species_packages), collapse = \", \"))\n  }\n\n  org_package &lt;- species_packages[[species]]\n\n  # Load the organism-specific package\n  suppressPackageStartupMessages(require(org_package, character.only = TRUE))\n\n  # Get all GO terms\n  go_terms &lt;- as.list(GOTERM)\n\n  # Extract GO IDs and their associated terms\n  go_ids &lt;- names(go_terms)\n  go_terms_text &lt;- character(length(go_terms))\n\n  for (i in seq_along(go_terms)) {\n    go_terms_text[i] &lt;- go_terms[[i]]@Term\n  }\n\n  # Search for GO terms that include the search term (case-insensitive)\n  indices &lt;- grep(search_term, go_terms_text, ignore.case = TRUE)\n  matched_go_ids &lt;- go_ids[indices]\n\n  # Retrieve genes associated with these GO IDs\n  # Construct the name of the GO to All Genes mapping object\n  org_prefix &lt;- sub(\"\\\\.db$\", \"\", org_package) # Remove \".db\" from package name\n  go2allels_name &lt;- paste0(org_prefix, \"GO2ALLEGS\")\n  go2allels &lt;- get(go2allels_name)\n\n  genes_entrez_list &lt;- mget(matched_go_ids, go2allels, ifnotfound = NA)\n\n  # Flatten the list and remove NAs\n  genes_entrez &lt;- unique(unlist(genes_entrez_list))\n  genes_entrez &lt;- genes_entrez[!is.na(genes_entrez)]\n\n  # Map Entrez Gene IDs to the specified ID type\n  # Get the organism-specific database object\n  org_db &lt;- get(org_package)\n\n  # Check if the requested id_type is valid\n  valid_id_types &lt;- columns(org_db)\n  if (!(id_type %in% valid_id_types)) {\n    stop(\"Invalid 'id_type'. Valid options are: \", paste(valid_id_types, collapse = \", \"))\n  }\n\n  # If id_type is ENTREZID, simply return the Entrez IDs\n  if (id_type == \"ENTREZID\") {\n    genes_ids &lt;- genes_entrez\n    names(genes_ids) &lt;- genes_entrez\n  } else {\n    genes_ids &lt;- mapIds(\n      org_db,\n      keys = genes_entrez,\n      column = id_type,\n      keytype = \"ENTREZID\",\n      multiVals = \"first\"\n    )\n  }\n\n\n  genes_ids\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#treemap-plot-with-highest-frequency-terms-used-as-labels-for-groups","title":"treemap plot with highest frequency terms used as labels for groups","text":"<p><code>rrvigo::treemapPlot</code> is nifty, but the labeling can leave a bit to be desired since it will only label by the largest or top-scored term in each cluster. This function labels instead by the top N highest frequency words in the terms for each cluster, which feels like a nicer representation than the other options. Like a mix of a wordcloud with a treemap.</p> <pre><code>#' treeMapPlot with frequency-based labels\n#' \n#' @param reducedTerms Data frame of reduced terms from reduceSimMatrix.\n#' @param nterms Number of terms to use as labels.\n#' @param size What to use for rectangle sizing. Can be either GO term's \"size\" or \"score\".\n#'   Defaults to \"score\".\n#' @param title Plot title. \n#' @param stopwords Vector of stopwords to ignore for term frequency calculation. \n#'   Defaults to English stopwords.\n#' @param ... other parameters sent to treemap::treemap()\n#' @return A list from the call to the `treemap()` function is silently returned\n#' @examples\n#' \\dontrun{\n#' go_analysis &lt;- read.delim(system.file(\"extdata/example.txt\", package=\"rrvgo\"))\n#' simMatrix &lt;- calculateSimMatrix(go_analysis$ID, orgdb=\"org.Hs.eg.db\", ont=\"BP\", method=\"Rel\")\n#' scores &lt;- setNames(-log10(go_analysis$qvalue), go_analysis$ID)\n#' reducedTerms &lt;- reduceSimMatrix(simMatrix, scores, threshold=0.7, orgdb=\"org.Hs.eg.db\")\n#' treemapPlotFreq(reducedTerms)\n#' }\n#'\n#' @author Jared Andrews\n#'\n#' @importFrom treemap treemap\n#' @export\ntreemapPlotFreq &lt;- function(reducedTerms, nterms = 6, size = \"score\", title = \"\", stoppers = stopwords(kind = \"en\"), ...) {\n\n  # For each cluster of terms, get frequency of \"term\", sort words by frequency, and take top nterms\n  freq.red.terms &lt;- data.frame()\n  for (c in unique(reducedTerms$cluster)) {\n    clusterTerms &lt;- reducedTerms[reducedTerms$cluster == c, ]\n    x &lt;- tm::Corpus(tm::VectorSource(clusterTerms$term))\n    tdm &lt;- tm::TermDocumentMatrix(x, control=list(removePunctuation=FALSE,\n                                                stopwords=stoppers))\n    m &lt;- as.matrix(tdm)\n    v &lt;- sort(rowSums(m), decreasing=TRUE)\n    d &lt;- data.frame(word=names(v), freq=v)\n    wds &lt;- d$word[seq(nterms)]\n    wds &lt;- wds[!is.na(wds)]\n    clusterTerms$parentTerm &lt;- paste(wds, collapse = \" \")\n    freq.red.terms &lt;- rbind(freq.red.terms, clusterTerms)\n  }\n\n  treemap::treemap(freq.red.terms, index=c(\"parentTerm\", \"term\"), vSize=size,\n                   type=\"index\", title=title,\n                   palette=rrvgo:::gg_color_hue(length(unique(reducedTerms$parent))),\n                   fontcolor.labels=c(\"#FFFFFFDD\", \"#00000080\"), bg.labels=0,\n                   border.col=\"#00000080\", ...)\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#group-barplot-of-highest-frequency-terms","title":"Group barPlot of highest frequency terms","text":"<p>This will plot the top 5 terms in each cluster by frequency and use them as the labels to summarize the group. Uses \"score\" to rank within each group.</p> <pre><code># Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(colorspace)\nlibrary(tm)\nlibrary(dittoSeq)\n\n# Function to generate the plot\nplot_clustered_terms &lt;- function(reduced_terms, stoppers = c(stopwords(kind = \"en\")),\n                                 color = \"#E69F00\", n_top_terms = 5, perc_shift = 0.05,\n                                 label_font_size = 5, xlab = \"-log10(adj.P)\") {\n\n  # Find the top n terms for each cluster\n  top_terms &lt;- reduced_terms %&gt;%\n    unnest_tokens(word, term, token = stringr::str_split, pattern = \" \") %&gt;%\n    filter(!word %in% stoppers) %&gt;%\n    rowwise() %&gt;%\n    mutate(word = removePunctuation(word, preserve_intra_word_dashes = TRUE)) %&gt;%\n    count(cluster, word, sort = TRUE) %&gt;%\n    group_by(cluster) %&gt;%\n    slice_max(n, n = n_top_terms, with_ties = FALSE) %&gt;%\n    summarise(terms = paste(word, collapse = \" \"))\n\n  # Merge the top terms back into the main data\n  data_with_terms &lt;- reduced_terms %&gt;%\n    left_join(top_terms, by = \"cluster\")\n\n  # Arrange data by cluster and score within cluster\n  data_with_terms &lt;- data_with_terms %&gt;%\n    arrange(desc(cluster), score) %&gt;%\n    mutate(term_order = factor(paste(\"Cluster\", cluster, \":\", term), \n                               levels = paste(\"Cluster\", cluster, \":\", term)))\n\n  # Create a numeric version of term_order for easier handling of segments\n  data_with_terms$term_index &lt;- as.numeric(data_with_terms$term_order)\n\n  # Calculate middle cluster\n  unique_clusters &lt;- sort(unique(data_with_terms$cluster))\n  middle_cluster &lt;- unique_clusters[ceiling(length(unique_clusters) / 2)]\n\n  # Assign colors based on distance from the middle cluster\n  data_with_terms &lt;- data_with_terms %&gt;%\n    mutate(color_adjusted = case_when(\n      cluster == middle_cluster ~ color,\n      cluster &lt; middle_cluster ~ darken(color, amount = (middle_cluster - cluster) * perc_shift),\n      cluster &gt; middle_cluster ~ lighten(color, amount = (cluster - middle_cluster) * perc_shift)\n    ))\n\n  # Create the plot\n  p &lt;- ggplot(data_with_terms, aes(y = term_order, x = score)) +\n    geom_bar(stat = \"identity\", show.legend = FALSE, fill = data_with_terms$color_adjusted) +\n    theme_classic() \n\n  # Add line segments and text for top terms\n  pp &lt;- p + \n    geom_segment(data = data_with_terms %&gt;% group_by(cluster) %&gt;% \n                     summarise(min_idx = min(term_index), max_idx = max(term_index), color_adjusted = color_adjusted),\n                 aes(y = min_idx - 0.05, yend = max_idx + 0.05, x = -0.1, xend = -0.1, color = color_adjusted),\n                 linetype = \"solid\", size = 1, color = rev((data_with_terms %&gt;% group_by(cluster))$color_adjusted)) +\n    scale_y_discrete(labels = str_wrap(top_terms$terms, width = 30), \n                     breaks = data_with_terms$term_order[(data_with_terms %&gt;% group_by(cluster) %&gt;% \n                                                              summarise(mid = ceiling(mean(term_index))))$mid]) + \n    scale_x_continuous(expand = c(0,0)) +\n    labs(x = xlab, y = NULL) +\n    theme(axis.line.y = element_blank(),\n          axis.ticks.y = element_blank(),\n          axis.text.y = element_text(size = label_font_size))\n\n  pp\n}\n\n\nplot_clustered_terms_top &lt;- function(reduced_terms, stoppers = c(stopwords(kind = \"en\")),\n                                 color = \"#E69F00\", n_top_terms = 5, n_top_clusters = NULL, perc_shift = 0.3,\n                                 label_font_size = 5, xlabel = \"score\") {\n\n  # Find the top n terms for each cluster\n  top_terms &lt;- reduced_terms %&gt;%\n    unnest_tokens(word, term, token = stringr::str_split, pattern = \" \") %&gt;%\n    filter(!word %in% stoppers) %&gt;%\n    rowwise() %&gt;%\n    mutate(word = removePunctuation(word, preserve_intra_word_dashes = TRUE)) %&gt;%\n    count(cluster, word, sort = TRUE) %&gt;%\n    group_by(cluster) %&gt;%\n    slice_max(n, n = n_top_terms, with_ties = FALSE) %&gt;%\n    summarise(terms = paste(word, collapse = \" \"))\n\n  # Merge the top terms back into the main data\n  data_with_terms &lt;- reduced_terms %&gt;%\n    left_join(top_terms, by = \"cluster\")\n\n  # Arrange data by cluster and score within cluster\n  data_with_terms &lt;- data_with_terms %&gt;%\n    arrange(desc(cluster), score) %&gt;%\n      group_by(cluster) %&gt;%\n    slice_max(score, n = 1, with_ties = FALSE)\n\n  # Limit to top N clusters by score, across groups\n  if (!is.null(n_top_clusters)) {\n    data_with_terms &lt;- data_with_terms %&gt;%\n      arrange(desc(score)) %&gt;%\n      head(n = n_top_clusters)\n  }\n\n  # Create the plot\n  ggplot(data_with_terms, aes(y = reorder(terms, score), x = score, fill = score)) +\n    geom_bar(stat = \"identity\", show.legend = TRUE) +\n    theme_classic() +\n      theme(axis.text.y = element_text(size = label_font_size)) +\n  scale_y_discrete(labels = function(x) str_wrap(x, width = 50)) +\n      scale_fill_gradient(low = Lighten(color, percent.change = perc_shift), high = Darken(color, percent.change = perc_shift)) +\n      xlab(xlabel)\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#how-to-run","title":"How to Run","text":"<pre><code># Get GO BP data, speeds up similarity calculation\nonts &lt;- c(\"BP\", \"CC\", \"MF\")\n\nbs.col &lt;- \"#E69F00\"\nfb.col &lt;- \"#56B4E9\"\n\nwt.col &lt;- \"grey30\"\nk27.col &lt;- \"#118002\"\n\nfor (ont in onts) {\n    gobp &lt;- GOSemSim::godata(\"org.Mm.eg.db\", ont = ont)\n\n    comps &lt;- c(\n                \"bs.k27m.up.unique\",\n                \"bs.wt.up.unique\",\n                \"ctx.k27m.up.unique\",\n                \"ctx.wt.up.unique\",\n                \"k27m.up.common\",\n                \"wt.up.common\",\n                \"wt.bs.up.unique\",\n                \"wt.ctx.up.unique\",\n                \"wt.bs.up.common\",\n                \"wt.ctx.up.common\")\n\n    # Ignore these words in freq calcs\n    stoppers &lt;- tm::stopwords(kind = \"en\")\n    stoppers &lt;- c(stoppers, \"regulation\", \"positive\", \"negative\", \"process\", \"cell\", \"activity\")\n\n    for (i in comps) {\n        if (startsWith(i, \"bs.wt.up\") | startsWith(i, \"ctx.wt.up\") | startsWith(i, \"wt.up.common\")) {\n            up.col &lt;- wt.col\n        } else if (startsWith(i, \"bs.k27m.up\") | startsWith(i, \"ctx.k27m.up\") | startsWith(i, \"k27m.up.common\")) {\n            up.col &lt;- k27.col\n        } else if (startsWith(i, \"wt.bs.up.unique\")) {\n            up.col &lt;- bs.col\n        } else if (startsWith(i, \"wt.ctx.up.unique\")) {\n            up.col &lt;- fb.col\n        } else {\n            up.col &lt;- \"magenta\"\n        }\n\n        message(i)\n        if (file.exists(paste0(\"./enrichments/de_sets/\", i, \"/enrichGO.\", ont, \".results.RDS\"))) {\n          enr.up &lt;- readRDS(paste0(\"./enrichments/de_sets/\", i, \"/enrichGO.\", ont, \".results.RDS\"))\n          enr.up &lt;- as.data.frame(enr.up)\n        } else {\n          enr.up &lt;- NULL\n        }\n\n        # Collapse similar terms, score by term size\n        enr.up.red &lt;- NULL\n        if (!is.null(enr.up)) {\n          if (nrow(enr.up) &gt; 2) {\n            enr.up.sim &lt;- calculateSimMatrix(enr.up$ID, \n                                             orgdb = \"org.Mm.eg.db\", ont = ont, semdata = gobp,\n                                             method = \"Rel\")\n\n            enr.up.scores &lt;- -log10(enr.up$p.adjust)\n            names(enr.up.scores) &lt;- enr.up$ID\n\n            enr.up.red.size &lt;- reduceSimMatrix(enr.up.sim, scores = \"size\", \n                                               threshold = 0.7, orgdb = \"org.Mm.eg.db\")\n\n            enr.up.red.unique &lt;- reduceSimMatrix(enr.up.sim, scores = \"uniqueness\", \n                                                 threshold = 0.7, orgdb = \"org.Mm.eg.db\")\n\n            enr.up.red.score &lt;- reduceSimMatrix(enr.up.sim, scores = enr.up.scores, \n                                                threshold = 0.7, orgdb = \"org.Mm.eg.db\")\n\n            write.table(enr.up.red.size, \n                        file = paste0(\"./enrichments/de_sets/\", i,\n                                      \"/enrichGO.\", ont, \".termsim.Reduced.size.0.7.txt\"), \n                        sep = \"\\t\", \n                      row.names = FALSE, quote = FALSE)\n\n            write.table(enr.up.red.unique, \n                        file = paste0(\"./enrichments/de_sets/\", i,\n                                      \"/enrichGO.\", ont, \".termsim.Reduced.uniqueness.0.7.txt\"), \n                        sep = \"\\t\", \n                      row.names = FALSE, quote = FALSE)\n\n            write.table(enr.up.red.score, \n                        file = paste0(\"./enrichments/de_sets/\", i,\n                                      \"/enrichGO.\", ont, \".termsim.Reduced.log10padj_scores.0.7.txt\"), \n                        sep = \"\\t\", \n                      row.names = FALSE, quote = FALSE)\n\n            # barPlots\n            pdf(paste0(\"./enrichments/de_sets/\", i, \"/enrichGO.\", ont, \".barplot.termsim.Reduced.size.0.7.pdf\"), width = 5, height = 6)\n            p &lt;- plot_clustered_terms_top(enr.up.red.size, color = up.col, n_top_terms = 5, xlabel = \"term size\", stoppers = stoppers)\n            print(p)\n            p &lt;- plot_clustered_terms_top(enr.up.red.size, color = up.col, n_top_terms = 5, n_top_clusters = 20, \n                                          xlabel = \"term size\", stoppers = stoppers) + ggtitle(\"top 20 clusters by score\")\n            print(p)\n            dev.off()\n\n            pdf(paste0(\"./enrichments/de_sets/\", i, \"/enrichGO.\", ont, \".barplot.termsim.Reduced.uniqueness.0.7.pdf\"), width = 5, height = 6)\n            p &lt;- plot_clustered_terms_top(enr.up.red.unique, color = up.col, n_top_terms = 5, xlabel = \"uniqueness\", stoppers = stoppers)\n            print(p)\n            p &lt;- plot_clustered_terms_top(enr.up.red.unique, color = up.col, n_top_terms = 5, n_top_clusters = 20, \n                                          xlabel = \"uniqueness\", stoppers = stoppers) + ggtitle(\"top 20 clusters by score\")\n            print(p)\n            dev.off()\n\n            pdf(paste0(\"./enrichments/de_sets/\", i, \"/enrichGO.\", ont, \".barplot.termsim.Reduced.log10padj_scores.0.7.pdf\"), width = 5, height = 6)\n            p &lt;- plot_clustered_terms_top(enr.up.red.score, color = up.col, n_top_terms = 5, xlabel = \"-log10(adj.pval)\", stoppers = stoppers)\n            print(p)\n            p &lt;- plot_clustered_terms_top(enr.up.red.score, color = up.col, n_top_terms = 5, n_top_clusters = 20, \n                                          xlabel = \"-log10(adj.pval)\", stoppers = stoppers) + ggtitle(\"top 20 clusters by score\")\n            print(p)\n            dev.off()\n\n          }\n        }\n    }\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#cnv-calling-from-methylation-array","title":"CNV Calling from Methylation Array","text":"<p>This spits out typical genome-wide CNV plots, segmentation files, bins, and IGV tracks from Illumina methylation arrays. Users can add details regions for labels if they'd like. When mixing both 450k and EPIC arrays, set <code>array_type = \"overlap\"</code>.</p> Using conumee <pre><code>library(\"minfi\")\nlibrary(\"conumee\")\nlibrary(\"IlluminaHumanMethylationEPICanno.ilm10b4.hg19\")\n\n#' @param meta Character scalar for the path to samplesheet with sample metadata, each row containing a sample.\n#' @param basedir Character scalar for the base directory containing IDATs.\n#' @param controls Character vector for control sample names found in \\code{name_col}.\n#' @param outdir Character scalar for output directory.\n#' @param chr Character vector indicating chromosomes to plot in genome plots. If provided, an additional\n#'   set of genome plots will be created with only these chromosomes.\n#' @param exclude_regions GRanges object containing regions to exclude from the CN plots.\n#' @param detail_regions GRanges object containing regions to label.\n#' @param array_type Character scalar indicating more array type. Options are \"450k\", \"EPIC\", or \"overlap\" for\n#'   datasets with mixed arrays.\n#' @param idat_cols Character scalar or vector containing column names for sample identifier columns to paste together.\n#'   This should be the IDAT ID.\n#' @param name_col Character scalar for column containing sample names.\nrun_conumee_CNV &lt;- function(meta, basedir, controls, outdir, chr = \"all\", exclude_regions = NULL, detail_regions = NULL, \n                            array_type = \"450k\", idat_cols = c(\"Sentrix_ID\", \"Sentrix_Position\"),\n                            name_col = \"Sample\") {\n  dir.create(outdir, showWarnings = FALSE, recursive = TRUE)\n\n  ## Load data.\n  meta &lt;- read.csv(meta)\n  meta$Basename &lt;- file.path(basedir, apply(meta[,idat_cols, drop = FALSE], MARGIN = 1, FUN = paste0, collapse = \"_\"))\n\n  samps &lt;- read.metharray.exp(targets = meta, force = TRUE)\n\n  samps &lt;- preprocessNoob(samps)\n\n  anno &lt;- CNV.create_anno(array_type = array_type, exclude_regions = exclude_regions, detail_regions = detail_regions)\n\n  # This is a bugfix for EPIC arrays and the probes in the annotations by default being screwed up. \n  if (array_type %in% c(\"EPIC\", \"overlap\")) {\n    anno@probes &lt;- anno@probes[names(anno@probes) %in% \n      names(minfi::getLocations(IlluminaHumanMethylationEPICanno.ilm10b4.hg19))]\n  }\n\n  ## CNV Calling\n  cn.data &lt;- CNV.load(samps)\n\n  sammies &lt;- unlist(pData(samps)[name_col])\n  sammies &lt;- sammies[!sammies %in% controls]\n\n  ## Plots &amp; Tables\n  pdf(paste0(outdir, \"/CNVplots.conumee.pdf\"), height = 9, width = 18)\n  for (s in sammies) {\n    s.data &lt;- rownames(pData(samps))[unlist(pData(samps)[name_col]) == s]\n    c.data &lt;- rownames(pData(samps))[unlist(pData(samps)[name_col]) %in% controls]\n    x &lt;- CNV.fit(cn.data[s.data], cn.data[c.data], anno)\n\n    x &lt;- CNV.bin(x)\n    x &lt;- CNV.segment(x)\n\n    CNV.genomeplot(x, main = s)\n\n    x &lt;- CNV.detail(x)\n    CNV.genomeplot(x, main = paste0(s, \" - detailed\"))\n\n    if (length(chr) &gt; 1) {\n      CNV.genomeplot(x, main = paste0(s, \" - \", paste(chr, collapse = \", \")), chr = chr)\n    }\n\n    CNV.write(x, what = \"segments\", file = paste0(outdir, \"/\", s, \".CNVsegments.seg\"))  \n    CNV.write(x, what = \"bins\", file = paste0(outdir, \"/\", s, \".CNVbins.igv\"))\n    CNV.write(x, what = \"detail\", file = paste0(outdir, \"/\", s, \".CNVdetail.txt\"))\n    CNV.write(x, what = \"probes\", file = paste0(outdir, \"/\", s, \".CNVprobes.igv\"))\n  }\n  dev.off()\n}\n\n## Detail regions can be made from a BED file if wanted, see the example data for format.\ndata(exclude_regions)\ndata(detail_regions)\n\nrun_conumee_CNV(meta = \"SampleMap.csv\", \n                array_type = \"EPIC\",\n                basedir = \"./\", \n                controls = c(\"Ctrl1\", \"Ctrl2\", \"Ctrl3\"), \n                outdir = \"./cnv\",\n                exclude_regions = exclude_regions,\n                detail_regions = detail_regions,\n                idat_cols = \"IDAT\",\n                name_col = \"Sample\")\n</code></pre>"},{"location":"Code_Snippets_Functions/#find-common-elements-from-multiple-vectors","title":"Find Common Elements from Multiple Vectors","text":"<pre><code>Reduce(intersect, list(a,b,c))\n</code></pre>"},{"location":"Code_Snippets_Functions/#differential-gene-expression-via-deseq2","title":"Differential Gene Expression via <code>DESeq2</code>","text":"<p>This is a super lazy function to run through a list of contrasts and create differential gene expression results for each.</p> <pre><code>#' Get DESeq2 Results\n#'\n#' This function obtains a set of comparisons from a DESeq2 analysis, given a named list of contrasts. It allows additional model \n#' parameters to be specified and a design matrix to be manually adjusted. \n#'\n#' @param dds An object of class DESeqDataSet.\n#' @param res.list A list of DESeq2 result tables. Allows the fuction to be run multiple times if needed and append to the same list.\n#' @param contrasts A named list of contrasts.\n#' @param user.mat A logical indicating whether a user-specified model matrix is provided. Defaults to FALSE.\n#' @param block A vector of additional terms to be considered in the model, beyond the main effect. Defaults to NULL.\n#' @param design The design formula or matrix. If a matrix is provided, ensure 'user.mat' is set to TRUE. Defaults to NULL.\n#' @param alpha The significance level for hypothesis testing. Defaults to 0.05.\n#' @param lfc.th A numeric vector of log2 fold-change thresholds. Defaults to c(log2(1.5), log2(2)).\n#' @param shrink.method The method used for shrinkage estimation. Defaults to \"apeglm\".\n#' @param outdir The directory where the output should be saved. Defaults to \"./de\".\n#' @param norm.ercc A logical indicating whether to normalize to ERCC spike-ins.\n#' @param BPPARAM The BiocParallelParam object specifying the parallel back-end to be used. Defaults to NULL.\n#' \n#' @return A list of DESeq2 result tables for the specified contrasts, saved to the specified output directory.\n#' \n#' @examples\n#' \\dontrun{\n#' get_DESEQ2_res(dds, res.list, contrasts, user.mat = TRUE, block = c(\"term1\", \"term2\"), \n#'                design = my_design, alpha = 0.01, lfc.th = c(log2(2), log2(3)), \n#'                shrink.method = \"normal\", outdir = \"./my_results\", BPPARAM = MulticoreParam(2))\n#' }\n#'\n#' @author Jared Andrews\nget_DESEQ2_res &lt;- function(dds, res.list, contrasts, user.mat = FALSE, block = NULL, \n                           design = NULL, alpha = 0.05, \n                           lfc.th = c(log2(1.25), log2(1.5)), shrink.method = \"apeglm\", \n                           outdir = \"./de\", norm.ercc = FALSE, BPPARAM = NULL) {\n\n  dir.create(file.path(outdir), showWarnings = FALSE, recursive = TRUE)\n\n  for (i in seq_along(contrasts)) {\n    rname &lt;- names(contrasts)[i]\n\n    # If user-supplied matrix, contrast must be in list format.\n    if (user.mat) {\n      con &lt;- contrasts[[i]]\n      message(\"Setting shrink.method to 'ashr' to work with list contrasts due to user-specified model matrix.\")\n      shrink.method &lt;- \"ashr\"\n    } else {\n      con &lt;- contrasts[[i]]\n      coef &lt;- paste(con[1], con[2], \"vs\", con[3], sep = \"_\")\n      dds[[con[1]]] &lt;- relevel(dds[[con[1]]], ref = con[3])\n    }\n\n    if (!is.null(design)) {\n      desgn &lt;- design\n    } else if (!is.null(block)) {\n      desgn &lt;- as.formula(paste0(\"~\",paste0(c(block, con[1]), collapse = \"+\")))\n    } else {\n      desgn &lt;- as.formula(paste0(\"~\", con[1]))\n    }\n\n    message(paste0(\"\\nDesign for \", paste(con[1], con[2], \"vs\", con[3], sep = \"_\"),\n                   \" is \", paste0(as.character(desgn))))\n\n    dds &lt;- DESeqDataSet(dds, design = desgn)\n\n    # Get size factor by spike-ins if specified.\n    if (norm.ercc) {\n      spikes &lt;- rownames(dds)[grep(\"^ERCC-\", rownames(dds))]\n      message(paste0(\"\\nCalculating size factors from \", length(spikes), \" ERCC spike-ins.\"))\n      dds &lt;- estimateSizeFactors(dds, controlGenes=rownames(dds) %in% spikes)\n    }\n\n    dds &lt;- DESeq(dds, BPPARAM = BPPARAM)\n\n    res1 &lt;- results(dds, contrast = con, alpha = alpha)\n    res1$ENSEMBL &lt;- rownames(res1)\n    res1$SYMBOL &lt;- rowData(dds)$SYMBOL\n\n    if (!is.null(shrink.method)) {\n      out.name &lt;- paste0(rname, \"-shLFC\")\n\n      # ashr does not need coef, this is to ensure no error with user-supplied model matrix/list contrasts\n      if (shrink.method == \"ashr\") {\n        coef &lt;- NULL\n      }\n      shrink &lt;- lfcShrink(dds, res = res1, coef = coef, type = shrink.method)\n      shrink$ENSEMBL &lt;- rownames(shrink)\n      shrink$SYMBOL &lt;- rowData(dds)$SYMBOL\n      rownames(shrink) &lt;- shrink$SYMBOL\n      shrink &lt;- as.data.frame(shrink)\n      res.list[[out.name]] &lt;- shrink\n      write.table(shrink, file = paste0(outdir, \"/\", rname, \".shrinkFC.padj.\", alpha, \".txt\"), \n                  row.names = FALSE, quote = FALSE, sep = \"\\t\")\n    }\n\n    rownames(res1) &lt;- res1$SYMBOL\n    res1 &lt;- as.data.frame(res1)\n    res.list[[rname]] &lt;- res1\n\n    write.table(res1, file = paste0(outdir, \"/\", rname, \".padj.\", alpha, \".txt\"), \n                  row.names = FALSE, quote = FALSE, sep = \"\\t\")\n\n    for (l in lfc.th) {\n\n      res &lt;- results(dds, contrast = con, alpha = alpha, lfcThreshold = l)\n      res$ENSEMBL &lt;- rownames(res)\n      res$SYMBOL &lt;- rowData(dds)$SYMBOL\n\n      if (!is.null(shrink.method)) {\n        # ashr does not need coef, this is to ensure no error with user-supplied model matrix/list contrasts\n        if (shrink.method == \"ashr\") {\n          coef &lt;- NULL\n        }\n        out.name &lt;- paste0(rname, \"-shLFC\", l)\n        shrink &lt;- lfcShrink(dds, res = res, coef = coef, type = shrink.method)\n        shrink$ENSEMBL &lt;- rownames(shrink)\n        shrink$SYMBOL &lt;- rowData(dds)$SYMBOL\n        rownames(shrink) &lt;- shrink$SYMBOL\n        shrink &lt;- as.data.frame(shrink)\n        res.list[[out.name]] &lt;- shrink\n        write.table(shrink, file = paste0(outdir, \"/\", rname, \".shrinkLFC_thresh.\", l,\".padj.\", alpha, \".txt\"), \n                  row.names = FALSE, quote = FALSE, sep = \"\\t\")\n      }\n\n      rownames(res) &lt;- res$SYMBOL\n      out.name &lt;- paste0(rname, \"-LFC\", l)\n      res &lt;- as.data.frame(res)\n      res.list[[out.name]] &lt;- res\n\n      write.table(res, file = paste0(outdir, \"/\", rname, \".LFC_thresh.\", l,\".padj.\", alpha, \".txt\"), \n                  row.names = FALSE, quote = FALSE, sep = \"\\t\")\n    }\n  }\n\n  return(res.list)\n}\n\nres &lt;- list()\n\ncontrasts = list(\"shPDGFRA_2.v.shScr\" = c(\"shRNA\", \"shPDGFRA_2\", \"shScr\"),\n                 \"shPDGFRA_3.v.shScr\" = c(\"shRNA\", \"shPDGFRA_3\", \"shScr\"),\n                 \"shZFP36L1_1.v.shScr\" = c(\"shRNA\", \"shZFP36L1_1\", \"shScr\"),\n                 \"shZFP36L1_2.v.shScr\" = c(\"shRNA\", \"shZFP36L1_2\", \"shScr\"),\n                 \"shPTPRZ1_3.v.shScr\" = c(\"shRNA\", \"shPTPRZ1_3\", \"shScr\"))\n\nres &lt;- get_DESEQ2_res(dds, res.list = res, contrasts = contrasts)\n</code></pre>"},{"location":"Code_Snippets_Functions/#jaccard-similaritydistance","title":"Jaccard Similarity/Distance","text":"<p>For comparing sets and whatnot. Closer to 1, the more similar the sets. <code>1 - jaccard</code> is the distance between two sets, which represents the dissimilarity between them.</p> <pre><code>jaccard &lt;- function(a, b) {\n    intersection = length(intersect(a, b))\n    union = length(a) + length(b) - intersection\n    return (intersection/union)\n}\n\na &lt;- c(\"TP53\", \"CDK2\", \"LAIR1\")\nb &lt;- c(\"TP53\", \"CDK1\", \"LAIR2\")\njaccard(a, b)\n</code></pre>"},{"location":"Code_Snippets_Functions/#shiny","title":"Shiny","text":""},{"location":"Code_Snippets_Functions/#increase-upload-bundle-max-size","title":"Increase upload bundle max size","text":"<p>This will bump it to 3GB (default is 1 GB).</p> <pre><code>options(rsconnect.max.bundle.size=3000*1024^2)\n</code></pre> <p>At times it may be necessary to add this to a <code>.rsconnect_profile</code> file in the app directory for it to be picked up properly for whatever reason.</p>"},{"location":"Code_Snippets_Functions/#python","title":"Python","text":"<p> This is content.</p>"},{"location":"Code_Snippets_Functions/#bashunix-tools","title":"Bash/Unix Tools","text":""},{"location":"Code_Snippets_Functions/#useful-bashrc-functions-aliases-etc","title":"Useful <code>.bashrc</code> Functions, Aliases, etc.","text":"<p>Stuff to cram into your <code>.bashrc</code> to make your life generally easier.</p>"},{"location":"Code_Snippets_Functions/#extract-any-type-of-compressed-file","title":"Extract Any Type of Compressed File","text":"<pre><code>function extract {\n if [ -z \"$1\" ]; then\n    # display usage if no parameters given\n    echo \"Usage: extract .\"\n else\nif [ -f $1 ] ; then\n        # NAME=${1%.*}\n        # mkdir $NAME &amp;&amp; cd $NAME\n        case $1 in\n          *.tar.bz2) tar xvjf $1 ;;\n          *.tar.gz) tar xvzf $1 ;;\n          *.tar.xz) tar xvJf $1 ;;\n          *.lzma) unlzma $1 ;;\n          *.bz2) bunzip2 $1 ;;\n          *.rar) unrar x -ad $1 ;;\n          *.gz) gunzip $1 ;;\n          *.tar) tar xvf $1 ;;\n          *.tbz2) tar xvjf $1 ;;\n          *.tgz) tar xvzf $1 ;;\n          *.zip) unzip $1 ;;\n          *.Z) uncompress $1 ;;\n          *.7z) 7z x $1 ;;\n          *.xz) unxz $1 ;;\n          *.exe) cabextract $1 ;;\n          *) echo \"extract: '$1' - unknown archive method\" ;;\n        esac\nelse\necho \"$1 - file does not exist\"\n    fi\nfi\n}\n</code></pre>"},{"location":"Code_Snippets_Functions/#concatenate-fastqs-for-given-sample","title":"Concatenate FASTQs for Given Sample","text":"<p>For merging reads across multiple lanes, etc.</p> <pre><code>function concat_fastq {\n\n\u00a0 \u00a0 sample=$1\n\n\u00a0 \u00a0 if [[ -z \"$sample\" ]]; then\n\u00a0 \u00a0 \u00a0 \u00a0 echo \"A sample name must be provided as an argument.\"\n\u00a0 \u00a0 \u00a0 \u00a0 return 1\n\u00a0 \u00a0 fi\n\n\n\u00a0 \u00a0 # Check if files for R2 exist\n\u00a0 \u00a0 if ls \"${sample}\"_L00*_R2_001.fastq.gz 1&gt; /dev/null 2&gt;&amp;1; then\n\u00a0 \u00a0 \u00a0 \u00a0 # This is a paired-end sample\n\u00a0 \u00a0 \u00a0 \u00a0 echo \"Processing paired-end sample: $sample\"\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Concatenate R1\n\u00a0 \u00a0 \u00a0 \u00a0 cat \"${sample}\"_L00*_R1_001.fastq.gz &gt; \"${sample}_merged_R1_001.fastq.gz\"\n\u00a0 \u00a0 \u00a0 \u00a0 if [[ $? -ne 0 ]]; then\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 echo \"An error occurred while concatenating R1 files.\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return 1\n\u00a0 \u00a0 \u00a0 \u00a0 fi\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Concatenate R2\n\u00a0 \u00a0 \u00a0 \u00a0 cat \"${sample}\"_L00*_R2_001.fastq.gz &gt; \"${sample}_merged_R2_001.fastq.gz\"\n\n\u00a0 \u00a0 \u00a0 \u00a0 if [[ $? -ne 0 ]]; then\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 echo \"An error occurred while concatenating R2 files.\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return 1\n\u00a0 \u00a0 \u00a0 \u00a0 fi\n\u00a0 \u00a0 else\n\n\u00a0 \u00a0 \u00a0 \u00a0 # This is a single-end sample\n\u00a0 \u00a0 \u00a0 \u00a0 echo \"Processing single-end sample: $sample\"\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Concatenate R1 only\n\u00a0 \u00a0 \u00a0 \u00a0 cat \"${sample}\"_L00*_R1_001.fastq.gz &gt; \"${sample}_merged_R1_001.fastq.gz\"\n\u00a0 \u00a0 \u00a0 \u00a0 if [[ $? -ne 0 ]]; then\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 echo \"An error occurred while concatenating R1 files.\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return 1\n\u00a0 \u00a0 \u00a0 \u00a0 fi\n\u00a0 \u00a0 fi\n\n\u00a0 \u00a0 echo \"Concatenation complete for sample: $sample\"\n}\n</code></pre> <p>To use from a directory of FASTQs: <pre><code>for sample_name in $(ls *_L00*_R1_001.fastq.gz | rev | cut -d'_' -f4- | rev | sort | uniq); do\n\u00a0 \u00a0 concat_fastq \"$sample_name\"\ndone\n</code></pre></p>"},{"location":"Code_Snippets_Functions/#recursively-get-file-paths-with-suffix","title":"Recursively Get File Paths with Suffix","text":"<p>Useful for grabbing FASTQs from seq runs and all.</p> <pre><code># Function to recursively get all files with a given suffix from a directory, \n# sort them, and output their full paths to a text file. \n# Usage: get_files_with_suffix_sorted &lt;directory&gt; &lt;suffix&gt; &lt;output_file&gt; \nfunction get_files_with_suffix { \n    local directory=$1 \n    local suffix=$2 \n    local output_file=$3 \n\n    # Ensure the directory exists \n    if [[ ! -d \"$directory\" ]]; then \n        echo \"The specified directory does not exist: $directory\" \n        return 1 \n    fi \n\n    # Use find to get files with the given suffix, sort them, and output to the specified file \n    find \"$directory\" -type f -name \"*.$suffix\" | sort &gt; \"$output_file\" \n} \n\n# Example usage: # get_files_with_suffix /path/to/directory .fastq.gz output_sorted.txt\n</code></pre>"},{"location":"Code_Snippets_Functions/#tar-and-gzip-directory","title":"<code>tar</code> and <code>gzip</code> Directory","text":"<pre><code>tar czf name_of_archive_file.tar.gz name_of_directory_to_tar\n</code></pre>"},{"location":"Code_Snippets_Functions/#remove-all-characters-up-to-delimiter","title":"Remove All Characters Up to Delimiter","text":"<p>Includes first instance of delimiter. ':' is the delimiter in this case.</p> <pre><code>sed 's/^[^:]*://' file\n</code></pre> <p>Useful for file renaming as well, e.g.: <pre><code>for f in *.idat.gz; do samp=$(echo \"$f\" | sed 's/^[^_]*_//'); mv \"$f\" \"$samp\"; done\n</code></pre></p>"},{"location":"Code_Snippets_Functions/#kill-all-lsf-jobs-with-string-in-name","title":"Kill All LSF Jobs with String in Name","text":"<p>For when you screw up an array or whatnot.</p> <pre><code> bjobs -w | grep 'bbsplit50' | awk '{print $1}' | xargs bkill\n</code></pre>"},{"location":"Code_Snippets_Functions/#file-manipulation-tasks","title":"File Manipulation Tasks","text":"<p>If you don't love data cleaning, you don't love bioinformatics. -some guy</p>"},{"location":"Code_Snippets_Functions/#randomly-downsample-bam-to-set-number-of-readsread-pairs","title":"Randomly Downsample BAM to Set Number of Reads/Read Pairs","text":"<p>For instance, to 5 million here. It will never keep a read but not its mate. From biostars.</p> <pre><code>reads=5000000\nbam=your.bam\nfraction=$(samtools idxstats $bam | cut -f3 | awk -v ct=$reads 'BEGIN {total=0} {total += $1} END {print ct/total}')\nsamtools view -b -s ${fraction} foo.bam &gt; sampled.bam\n</code></pre>"},{"location":"Code_Snippets_Functions/#bam-to-fastq","title":"BAM to FASTQ","text":"<p>Gimme them reads back. Note that these may not be identical to the original FASTQ files if unaligned reads weren't retained in the BAM file. Note this is for an IBM LSF cluster, just yoink the <code>bamtofastq</code> command if you're running locally.</p> <pre><code>#!/bin/bash\nmodule load biobambam\n\nfor f in *.bam; do\n\n\u00a0 \u00a0 base=\"${f%%.bam}\"\n\n\u00a0 \u00a0 bsub -P xeno -J bambam -B -N -n 4 -R \"rusage[mem=4GB]\" -M 4GB -q priority \"bamtofastq F=$base.1.fastq.gz F2=$base.2.fastq.gz \\\n    \u00a0 \u00a0 gz=1 filename=$f;\"\n\ndone\n</code></pre>"},{"location":"Code_Snippets_Functions/#extract-random-reads-from-fastq","title":"Extract Random Reads from FASTQ","text":"<p>For checking or whatnot. Change <code>samplerate</code> to extract a given percentage of reads, set to 0.1% here. <code>#</code> is used by bbmap to fill in 1 &amp; 2, so this is for a paired end sample and will return two output files. Can also use <code>in1</code>, <code>in2</code>, <code>out1</code>, and <code>out2</code> if you'd prefer.</p> <pre><code>module load bbmap\nreformat.sh in=thefastq_R#_001.fastq.gz out=thefastq_R#_001.subsampled.fastq.gz samplerate=0.001\n\n# Or if a specific number of reads (pairs) are desired, e.g. 61,111,111 for 5x coverage with paired 150 bp read WGS.\nreformat.sh in=thefastq_R#_001.fastq.gz out=thefastq_R#_001.subsampled.fastq.gz samplereadstarget=61111111\n# 10x coverage with 150 bp reads.\nreformat.sh in=thefastq_R#_001.fastq.gz out=thefastq_R#_001.subsampled.fastq.gz samplereadstarget=122222222\n\n# 5x coverage with paired 100 bp read WGS.\nreformat.sh in=thefastq_R#_001.fastq.gz out=thefastq_R#_001.subsampled.fastq.gz samplereadstarget=91666666\n# 10x coverage with 100 bp reads.\nreformat.sh in=thefastq_R#_001.fastq.gz out=thefastq_R#_001.subsampled.fastq.gz samplereadstarget=183333333\n</code></pre>"},{"location":"Code_Snippets_Functions/#remove-n-characters-from-end-of-field-in-csv","title":"Remove N Characters from End of Field in CSV","text":"<p>For removing PAM sequence, etc.</p> <pre><code>awk -F, -v OFS=',' '{ $2=substr($2, 1, length($2)-3) } 1' input.csv &gt; output.csv\n</code></pre>"},{"location":"Code_Snippets_Functions/#sort-and-index-bams","title":"Sort and Index BAMS","text":"<pre><code>module load samtools\n\nfor f in *.bam; \n    do echo \"$f\"; \n    fb=$(basename \"$f\" .bam); \n    samtools sort -@ 8 -T \"$fb\" -o \"$fb\".sorted.bam \"$f\"; \n    samtools index \"$fb\".sorted.bam; \ndone\n</code></pre>"},{"location":"Code_Snippets_Functions/#bed-to-gff","title":"BED to GFF","text":"<p>I hate ROSE so much. GFF is 1-based, half closed, start needs to shift by one. Ignores anything past first 4 columns.</p> <pre><code># Assuming unique ID in column 4\nfor b in *.bed; do\n    bb=$(basename \"$b\" .bed);\n    awk 'BEGIN{OFS=\"\\t\"}; {print $1,$4,\".\",$2-1,$3,\".\",\".\",\".\",$4}' \"$b\" &gt; \"$bb\".gff;\ndone\n</code></pre>"},{"location":"Tutorials/scRNA_mutation_check/","title":"Checking Mutation Status in scRNA-seq Data","text":"<p>Sometimes, it's useful to look for known mutations in your scRNA-seq reads, especially if you expect a mutation to be present in certain populations and not others, e.g. an inducible model system or a recurrent tumor versus a diagnostic one.</p> <p>This process is relatively simple, though somewhat annoying. Let us delve into that annoyance now.</p> <p>A Note of Warning</p> <p>Note that this process is subject to high amounts of ambiguity. Given the sparsity of most scRNA-seq datasets, there may not be any reads for a given variant, especially if the gene is not highly expressed. Even if there is coverage, a WT call does not mean that the record is actually WT - it may only have a single read, so the other allele could well be mutant. Point being, you can really only tell if there is any support for the alternate allele in a given cell, not that the cell is WT.</p>"},{"location":"Tutorials/scRNA_mutation_check/#the-mutations","title":"The Mutation(s)","text":"<p>In this case, I only care about one mutation, so I handmade my VCF for the H3.3K27M mutation for mouse (mm10):</p> <pre><code>##fileformat=VCFv4.2\n#CHROM  POS ID  REF ALT QUAL    FILTER  INFO\nchr1    180811844   .   T   A   .   PASS    .\n</code></pre> <p>Ultimately, you just need a VCF of mutations derived from the same reference as your single cell data. If you have matched bulk WGS or WES data, variants called from that can be used. You can call variants from the scRNA-seq data itself, but it isn't recommended and won't be covered here. Use the GATK RNA-seq variant discovery best practices for that.</p> <p>This file needs to be bgzipped and indexed via <code>tabix</code> as well.</p> <pre><code>bgzip k27m.vcf\ntabix k27m.vcf.gz\n</code></pre>"},{"location":"Tutorials/scRNA_mutation_check/#the-single-cell-dataset","title":"The Single Cell Dataset","text":"<p>For your scRNA-seq dataset, you need aligned reads in BAM format, position sorted. Acquire these however you want, STARsolo, CellRanger, whatever. CellRanger BAMs will work by default.</p> <p>You also need a list of cell barcodes in the dataset - the <code>barcodes.tsv.gz</code> file output by CellRanger works.</p>"},{"location":"Tutorials/scRNA_mutation_check/#using-vartrix","title":"Using Vartrix","text":"<p>vartrix is a tool built by 10X to genotype specific sites in scRNA-seq data for known mutations. </p>"},{"location":"Tutorials/scRNA_mutation_check/#install","title":"Install","text":"<p>Via conda:</p> <pre><code>conda install -c bioconda vartrix\n</code></pre>"},{"location":"Tutorials/scRNA_mutation_check/#running","title":"Running","text":"<p>Pretty simple to run. Ya just feed in your VCF, the bam, the genome, the barcodes, and an output name. Below is a script to submit LSF jobs for a directory containing CellRanger runs. I use the raw feature barcodes, as I am doing my own cell calling with alevin-fry counts for my downstream analyses, so I don't want any of my potential cells filtered out.</p> <pre><code>#!/bin/bash\nmodule load conda3/202105\nconda activate vartrix\n\nfor f in ./cellranger_v6/*; do\n    echo \"$f\";\n    samp=$(basename \"$f\")\n\n    bsub -P dnb -J vartrix_$samp -q standard -n 4 -R \"rusage[mem=4000] span[hosts=1]\" vartrix \\\n                     -v k27m.vcf.gz \\\n                     -b \"$f\"/outs/possorted_genome_bam.bam \\\n                     -f ./refdata-gex-mm10-2020-A/fasta/genome.fa \\\n                     -c \"$f\"/outs/raw_feature_bc_matrix/barcodes.tsv.gz \\\n                     -o ./vartrix/\"$samp\".K27M_vartrix.mtx\n\ndone\n</code></pre> <p>Edit as needed, change to full paths, whatever. Run the above script via <code>bash vartrix.sh</code> assuming you saved it as such. It should be run from the directory above the one containing all your CellRanger runs.</p>"},{"location":"Tutorials/scRNA_mutation_check/#using-the-output","title":"Using the Output","text":"<p>This will spit out <code>.mtx</code> files for each sample, which we likely want to get into R and slapped onto our single cell object. I use Bioconductor packages, so my object is a <code>SingleCellExperiment</code>. Seurat will be similar, and the vartrix Github has an example of how to pull stuff out. I know I only have one variant, so I just want to tack it onto my SCE's <code>colData</code>.</p> <pre><code># Get Sample files.\nsamp.files &lt;- list.files(\"./10X_scRNA_v3/processed/vartrix\", \nrecursive = FALSE)\n\nsamp.ids &lt;- c(\"P14K-1\",\"P14K-2\",\"P14K-3\",\"P14K-4\",\n              \"P14-1\",\"P14-2\",\"P14-3\",\"P14-4\",\n              \"P21K-1\",\"P21K-2\",\"P21K-3\",\"P21K-4\",\n              \"P21-1\", \"P21-2\",\"P21-3\",\"P21-4\",\n              \"P4K-4\",\"P4K-2\",\"P4K-3\",\"P4K-1\",\n              \"P4-2\",\"P4-3\",\"P4-1\")\n\nfirst &lt;- TRUE\n\nall.k27m &lt;- data.frame()\n\nfor (samp in seq_along(samp.files)) {\n  mm &lt;- readMM(paste0(\"./10X_scRNA_v3/processed/vartrix/\", samp.files[samp]))\n  sbase &lt;- unlist(strsplit(samp.files[samp], \".\", fixed = TRUE))[1]\n  bars &lt;- read.table(paste0(\"./10X_scRNA_v3/processed/cellranger_v6/\", sbase, \n                            \"/outs/raw_feature_bc_matrix/barcodes.tsv.gz\"), \n                     header = FALSE)\n  mm &lt;- as.data.frame(mm)\n  colnames(mm) &lt;- bars$V1\n  colnames(mm) &lt;- paste0(samp.ids[samp], \"_\", colnames(mm))\n\n  if (first) {\n    all.k27m &lt;- mm\n    first &lt;- FALSE\n  } else {\n    all.k27m &lt;- cbind(all.k27m, mm)\n  }\n}\n</code></pre> <p>Check that all our cells in our <code>SCE</code> object named <code>sce</code> are found.</p> <pre><code>table(colnames(sce) %in% colnames(all.k27m))\n</code></pre> <p>Which they are. So now add the calls to the metadata.</p> <pre><code>rownames(all.k27m) &lt;- \"chr1_180811844\"\nall.k27m &lt;- all.k27m[,colnames(sce)]\nall.k27m &lt;- as.data.frame(t(all.k27m))\n\n# No reads detected\nall.k27m$V1 &lt;- stringr::str_replace(as.character(all.k27m$V1), \"0\", \"Unknown\")\n# Only ref detected\nall.k27m$V1 &lt;- stringr::str_replace(as.character(all.k27m$V1), \"1\", \"Ref_Only\")\n# Only alt detected\nall.k27m$V1 &lt;- stringr::str_replace(as.character(all.k27m$V1), \"2\", \"Mut_Only\")\n# Both alleles detected\nall.k27m$V1 &lt;- stringr::str_replace(as.character(all.k27m$V1), \"3\", \"Mut_WT\")\n\nsce$H3K27M_gt &lt;- all.k27m$V1\n</code></pre> <p>Great, now my <code>SCE</code> contains a column containing the genotype info, so we can plot our calls. </p> <pre><code>dittoDimPlot(sce, \"H3K27M_gt\", reduction.use = paste0(\"UMAP_m.dist0.2_n.neigh10\"), \n             do.raster = TRUE, color.panel = c(\"red\", \"orange\", \"black\", \"grey80\"), \n             order = \"decreasing\", size = 0.5) + theme(aspect.ratio = 1)\n</code></pre> <p></p> <p>Looks pretty decent. See a few pops that didn't get much induction, and some that did, which was to be expected.</p>"},{"location":"some_day_list/The_Some_Day_List/","title":"The \"some day\" List","text":"<p>Stuff that I'd like to get to at some point that isn't important enough to prioritize now.</p>"},{"location":"some_day_list/The_Some_Day_List/#development","title":"Development","text":"<ul> <li>Cram convenience/plotting functions into a R package for ease of maintenance/sharing.</li> <li>Find a way to summarize lots of GO terms into a human interpretable output that is both succinct and doesn't suck.<ul> <li>Fine tune an LLM and use RAG with the term descriptions?</li> <li>Preferably from within R without relying on external setup to run models.</li> </ul> </li> <li>Write up CRISPRball for JOSS or such &amp; submit.<ul> <li>Get public version live on DMZ VM.</li> </ul> </li> <li>Make IBET more performant.<ul> <li>Avoid complete re-plotting when adding labels.</li> <li>Add option to add labels automatically on highlighted gene(sets).</li> <li>Add apps to summarize/display GSEA and enrichment results for typical RNA-seq analyses.</li> </ul> </li> <li>Make the nf-core Cut &amp; Run pipeline script for fragment length histograms more memory efficient by changing from using <code>np.array</code> for each iteration to a list and concatenating the list objects into an array at the end.<ul> <li>This sucker takes like 500+ GB of memory for large datasets unnecessarily.</li> </ul> </li> <li>Figure out how to get the latest DepMap releases into the depmap R package</li> <li>Add methylation array viz function and Shiny app to sesame.</li> </ul>"},{"location":"some_day_list/The_Some_Day_List/#data-processing","title":"Data Processing","text":"<ul> <li>Typical <code>params.yaml</code> files for nf-core pipelines pointing to our reference data rather than having that crammed into configs.</li> <li>Template notebooks for ATAC-seq.</li> <li>Template notebooks for ChIP-seq/CnR.</li> <li>Set up nf-core rnafusion for easy running on RNA-seq data.</li> </ul>"},{"location":"some_day_list/The_Some_Day_List/#reference-data","title":"Reference Data","text":"<ul> <li>Get genesets from: https://www.science.org/doi/10.1126/science.add7046</li> <li>Make combined reference genomes for nf-core pipelines, e.g. mm10 + hg38. GTFs and FASTAs, with clear species indicators.<ul> <li>At least for RNA-seq, this takes advantage of the fractional counts based on probability (EM) from salmon for ambiguous reads.</li> <li>Have clear scripts for creation.</li> </ul> </li> </ul>"},{"location":"some_day_list/The_Some_Day_List/#organization","title":"Organization","text":"<ul> <li>List all interactive reports/apps on wiki.</li> </ul>"}]}